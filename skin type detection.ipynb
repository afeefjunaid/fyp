{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Noisy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_exts = ['jpg', 'jpeg', 'png', 'bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "\n",
    "data_dir = 'skinType'\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(image_path)    # print the path of the image with unknown extension\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image:\" .format(image_path))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [16,32]\n",
    "for size in batch_size:\n",
    "   data = tf.keras.utils.image_dataset_from_directory('skinType', batch_size=size, image_size=(256, 256), shuffle=True) #Data pipeline\n",
    "\n",
    "class_names = data.class_names #get the class names\n",
    "print(class_names)\n",
    "\n",
    "data_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "\n",
    "batch = data_iterator.next() #get the next batch of data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape # shape of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1] # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "rows = 4\n",
    "cols = 8\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20, 12))\n",
    "fig.suptitle('Sample Images with Class Labels', fontsize=16)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display images in grid\n",
    "for idx, (image, label) in enumerate(zip(batch[0][:32], batch[1][:32])):\n",
    "    # Get class name from label index\n",
    "    class_name = class_names[label]\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx].imshow(image.astype(\"uint8\"))\n",
    "    axes[idx].set_title(f'{class_name}', fontsize=8)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Add color-coded legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=f'C{i}', markersize=10, \n",
    "                             label=name) for i, name in enumerate(class_names)]\n",
    "fig.legend(handles=legend_elements, loc='center right')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)  # Make room for legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y : ((x/255),y)) #normalizing the data  \n",
    "scaled_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "batch = scaled_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].max() #max value in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.7) #70% of the data for training\n",
    "val_size = int(len(data) * 0.2) #20% of the data for validation\n",
    "test_size = int(len(data) * 0.1) #10% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size) #take the first 70% of the data for training\n",
    "val = data.skip(train_size).take(val_size) #skip the first 70% and take the next 20% for validation\n",
    "test = data.skip(train_size + val_size).take(test_size) #skip the first 90% and take the next 10% for testing\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomTranslation, RandomContrast, RandomCrop\n",
    "# filter size = 3x3\n",
    "# input shape = 256x256x3\n",
    "# stride = 1\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = batch[0].shape[0]\n",
    "model = Sequential() #initialize the model\n",
    "\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),         # Flip images both horizontally and vertically\n",
    "    RandomRotation(0.4),                           # Rotate images up to 40% in both directions\n",
    "    RandomZoom(height_factor=(-0.2, 0.2),          # Random zoom in/out\n",
    "               width_factor=(-0.2, 0.2)),\n",
    "    RandomTranslation(height_factor=0.2,           # Translate images up to 20% in height\n",
    "                      width_factor=0.2),           # Translate images up to 20% in width\n",
    "    RandomContrast(0.2),                           # Adjust contrast randomly\n",
    "    RandomCrop(IMAGE_SIZE - 20, IMAGE_SIZE - 20),  # Crop random parts of the image\n",
    "    tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE)  # Resize back to target size\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what is the expected dimension order for channel\n",
    "from tensorflow.keras import backend as k\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "batch_input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "chanDim = -1\n",
    "if k.image_data_format() == \"channels_first\":\n",
    "    input_shape = (CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    batch_input_shape = (BATCH_SIZE, CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    chanDim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "model_dir = '../saved_models'\n",
    "log_dir = os.path.join(model_dir, 'logs')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(model_dir, 'best_model.keras'),\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "final_model_path = os.path.join(model_dir, 'final_model.keras')\n",
    "model.save(final_model_path)\n",
    "print(f\"Model saved to {final_model_path}\")\n",
    "from matplotlib import pyplot as plt\n",
    "rows = 4\n",
    "cols = 8\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20, 12))\n",
    "fig.suptitle('Sample Images with Class Labels', fontsize=16)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display images in grid\n",
    "for idx, (image, label) in enumerate(zip(batch[0][:32], batch[1][:32])):\n",
    "    # Get class name from label index\n",
    "    class_name = class_names[label]\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx].imshow(image.astype(\"uint8\"))\n",
    "    axes[idx].set_title(f'{class_name}', fontsize=8)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Add color-coded legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=f'C{i}', markersize=10, \n",
    "                             label=name) for i, name in enumerate(class_names)]\n",
    "fig.legend(handles=legend_elements, loc='center right')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)  # Make room for legend\n",
    "plt.show()\n",
    "\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "train = data.take(train_size) #take the first 70% of the data for training\n",
    "val = data.skip(train_size).take(val_size) #skip the first 70% and take the next 20% for validation\n",
    "test = data.skip(train_size + val_size).take(test_size) #skip the first 90% and take the next 10% for testing\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "img_exts = ['jpg', 'jpeg', 'png', 'bmp']\n",
    "data_dir = 'skinType'\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(image_path)    # print the path of the image with unknown extension\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image:\" .format(image_path))\n",
    "batch_size = [16,32]\n",
    "for size in batch_size:\n",
    "   data = tf.keras.utils.image_dataset_from_directory('skinType', batch_size=size, image_size=(256, 256), shuffle=True) #Data pipeline\n",
    "\n",
    "class_names = data.class_names #get the class names\n",
    "print(class_names)\n",
    "\n",
    "data_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "\n",
    "batch = data_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].shape # shape of the batch\n",
    "       \n",
    "batch[1] # labels\n",
    "\n",
    "data = data.map(lambda x,y : ((x/255),y)) #normalizing the data  \n",
    "scaled_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "batch = scaled_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].max() #max value in the batch\n",
    "\n",
    "len(data)\n",
    "\n",
    "train_size = int(len(data) * 0.7) #70% of the data for training\n",
    "val_size = int(len(data) * 0.2) #20% of the data for validation\n",
    "test_size = int(len(data) * 0.1) #10% of the data for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from transformers import ViTForImageClassification, ViTConfig\n",
    "# from PIL import Image\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # Ensure GPU is used if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# # Dataset Directories (use raw string to avoid escape sequence issues)\n",
    "# data_dir = r'D:\\FAST\\Semester 8\\Final Year Project\\Skin Disease Dataset\\Oily-Dry-Skin-Types'\n",
    "\n",
    "# # Custom Dataset Class\n",
    "# class SkinTypeDataset(Dataset):\n",
    "#     def __init__(self, root_dir, transform=None):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "#         self.classes = ['dry', 'normal', 'oily']\n",
    "#         self.image_paths = []\n",
    "\n",
    "#         for label in self.classes:\n",
    "#             class_dir = os.path.join(root_dir, label)\n",
    "#             if os.path.exists(class_dir):\n",
    "#                 for img_file in os.listdir(class_dir):\n",
    "#                     img_path = os.path.join(class_dir, img_file)\n",
    "#                     if os.path.isfile(img_path):\n",
    "#                         self.image_paths.append((img_path, label))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path, label = self.image_paths[idx]\n",
    "#         image = Image.open(img_path).convert('RGB')\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         label = self.classes.index(label)\n",
    "#         return image, label\n",
    "\n",
    "# # Data Preprocessing\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "# ])\n",
    "\n",
    "# # Load Datasets\n",
    "# train_dataset = SkinTypeDataset(os.path.join(data_dir, 'train'), transform=transform)\n",
    "# val_dataset = SkinTypeDataset(os.path.join(data_dir, 'valid'), transform=transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# # GAN Generator Model\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, z_dim, img_channels):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(z_dim, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 224 * 224 * img_channels),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         output = self.net(z).view(-1, img_channels, 224, 224)\n",
    "#         return output\n",
    "\n",
    "# img_channels = 3\n",
    "# z_dim = 100\n",
    "# generator = Generator(z_dim, img_channels).to(device)\n",
    "\n",
    "# # Load Pre-trained ViT Model (with correct classifier size)\n",
    "# config = ViTConfig.from_pretrained('google/vit-base-patch16-224', num_labels=3)\n",
    "# model = ViTForImageClassification(config)\n",
    "# model.to(device)\n",
    "\n",
    "# # Loss and Optimizers\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# gan_optimizer = torch.optim.Adam(generator.parameters(), lr=2e-4)\n",
    "\n",
    "# # Training Loop\n",
    "# def train_model(model, train_loader, val_loader, generator, epochs=1):\n",
    "#     print(f\"Training on {device}...\")\n",
    "\n",
    "#     scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))  # Handle GPU/CPU\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         generator.train()\n",
    "#         total_loss = 0\n",
    "\n",
    "#         for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#             # GAN augmentation\n",
    "#             z = torch.randn(images.size(0), z_dim, device=device)\n",
    "#             fake_images = generator(z)\n",
    "\n",
    "#             # Ensure generated images match dimensions\n",
    "#             if fake_images.shape != images.shape:\n",
    "#                 fake_images = torch.nn.functional.interpolate(fake_images, size=(224, 224))\n",
    "\n",
    "#             # Combine real and fake images\n",
    "#             combined_images = torch.cat((images, fake_images), dim=0)\n",
    "#             combined_labels = torch.cat((labels, labels), dim=0)\n",
    "\n",
    "#             # Train ViT Model\n",
    "#             optimizer.zero_grad()\n",
    "#             with torch.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "#                 outputs = model(combined_images).logits\n",
    "#                 loss = criterion(outputs, combined_labels)\n",
    "\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#             # Display Progress\n",
    "#             if (batch_idx + 1) % 10 == 0:\n",
    "#                 print(f\"Epoch [{epoch + 1}/{epochs}], Step [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#         # Evaluate after each epoch\n",
    "#         val_acc = evaluate_model(model, val_loader)\n",
    "#         print(f\"Epoch [{epoch + 1}/{epochs}] - Avg Loss: {total_loss / len(train_loader):.4f} - Val Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "#     torch.save(model.state_dict(), 'skin_type_model.pth')\n",
    "#     print(\"Training complete! Model saved as 'skin_type_model.pth'.\")\n",
    "\n",
    "# # Evaluation Function\n",
    "# def evaluate_model(model, loader):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in loader:\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = model(images).logits\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#             total += labels.size(0)\n",
    "\n",
    "#     return 100 * correct / total\n",
    "\n",
    "# # Train the Model\n",
    "# train_model(model, train_loader, val_loader, generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to make VIT and GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "from sklearn.metrics import classification_report, roc_auc_score, mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "import torch\n",
    "# Ensure TensorFlow uses the GPU if available\n",
    "# GPU Detection using PyTorch\n",
    "print(\"Number of GPUs: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Dataset directory\n",
    "data_dir = 'skinType'\n",
    "\n",
    "# Image Extensions\n",
    "img_exts = ['jpg', 'jpeg', 'png', 'bmp']\n",
    "\n",
    "# Data Cleaning\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(\"Removing:\", image_path)\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image:\", image_path)\n",
    "\n",
    "# Parameters\n",
    "epochs = 3\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "batch_sizes = [4, 8, 16, 32, 64]\n",
    "optimizers = {'adam': Adam, 'sgd': SGD, 'rmsprop': RMSprop, 'adagrad': Adagrad, 'adadelta': Adadelta}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Load dataset and preprocess\n",
    "def load_data(batch_size):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir, batch_size=batch_size, image_size=(256, 256), shuffle=True)\n",
    "    dataset = dataset.map(lambda x, y: (x / 255.0, y))\n",
    "    return dataset\n",
    "\n",
    "# Split dataset\n",
    "def split_data(dataset):\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(total_size * 0.7)\n",
    "    val_size = int(total_size * 0.2)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    train_ds = dataset.take(train_size)\n",
    "    val_ds = dataset.skip(train_size).take(val_size)\n",
    "    test_ds = dataset.skip(train_size + val_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "# Build simple GAN\n",
    "def build_gan():\n",
    "    # Generator\n",
    "    generator = tf.keras.Sequential([\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.Dense(256 * 256 * 3, activation='tanh'),\n",
    "        layers.Reshape((256, 256, 3))\n",
    "    ])\n",
    "\n",
    "    # Discriminator\n",
    "    discriminator = tf.keras.Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "# Build Vision Transformer (ViT)\n",
    "def build_vit():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(len(os.listdir(data_dir)), activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate models\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, roc_auc_score, mean_squared_error\n",
    "import json\n",
    "\n",
    "def train_and_evaluate():\n",
    "    results = []\n",
    "    \n",
    "    # Loop over batch sizes\n",
    "    for batch_size in batch_sizes:\n",
    "        dataset = load_data(batch_size)\n",
    "        train_ds, val_ds, test_ds = split_data(dataset)\n",
    "\n",
    "        # Loop over learning rates\n",
    "        for lr in learning_rates:\n",
    "            # Loop over optimizers\n",
    "            for opt_name, opt_class in optimizers.items():\n",
    "                optimizer = opt_class(learning_rate=lr)\n",
    "\n",
    "                # Initialize ViT model\n",
    "                vit_model = build_vit()\n",
    "                vit_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "                \n",
    "                # Train the ViT model\n",
    "                history = vit_model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=1)\n",
    "\n",
    "                # Evaluate the ViT model\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                y_prob = []  # To store the predicted probabilities\n",
    "\n",
    "                # Iterate over the test dataset\n",
    "                for x_batch, y_batch in test_ds:\n",
    "                    # Move data to GPU if available\n",
    "                    x_batch = x_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "\n",
    "                    # Make predictions using ViT model\n",
    "                    with torch.no_grad():\n",
    "                        outputs = vit_model(x_batch)\n",
    "                        probs = F.softmax(outputs, dim=1)  # Get predicted probabilities\n",
    "                        _, predicted = torch.max(outputs, 1)  # Get the class predictions\n",
    "\n",
    "                    y_true.extend(y_batch.cpu().numpy())\n",
    "                    y_pred.extend(predicted.cpu().numpy())\n",
    "                    y_prob.extend(probs.cpu().numpy())  # Store the probabilities\n",
    "\n",
    "                # Compute classification report\n",
    "                report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "                # Compute ROC AUC score (use probabilities, not hard class predictions)\n",
    "                auc_score = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
    "\n",
    "                # Compute RMSE\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "                # Store the results\n",
    "                result = {\n",
    "                    'batch_size': batch_size,\n",
    "                    'learning_rate': lr,\n",
    "                    'optimizer': opt_name,\n",
    "                    'accuracy': report['accuracy'],\n",
    "                    'precision': report['macro avg']['precision'],\n",
    "                    'recall': report['macro avg']['recall'],\n",
    "                    'f1-score': report['macro avg']['f1-score'],\n",
    "                    'roc_auc': auc_score,\n",
    "                    'rmse': rmse\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "    # Save the results to a JSON file\n",
    "    with open('results.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage (Ensure that the functions `load_data`, `split_data`, `build_vit`, and `optimizers` are defined elsewhere in your code)\n",
    "\n",
    "# Assuming device is already set up\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Example batch sizes, learning rates, optimizers, and other parameters\n",
    "batch_sizes = [32, 64]\n",
    "learning_rates = [1e-3, 1e-4]\n",
    "optimizers = {'Adam': torch.optim.Adam, 'SGD': torch.optim.SGD}\n",
    "epochs = 10\n",
    "\n",
    "# Call the function\n",
    "results = train_and_evaluate()\n",
    "\n",
    "# Optionally, print or plot results\n",
    "print(results)\n",
    "\n",
    "# Plot Results\n",
    "def plot_results(results):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracies = [res['accuracy'] for res in results]\n",
    "    plt.plot(accuracies, label='Accuracy')\n",
    "\n",
    "    # Precision\n",
    "    precisions = [res['precision'] for res in results]\n",
    "    plt.plot(precisions, label='Precision')\n",
    "\n",
    "    # Recall\n",
    "    recalls = [res['recall'] for res in results]\n",
    "    plt.plot(recalls, label='Recall')\n",
    "\n",
    "    # F1-Score\n",
    "    f1_scores = [res['f1-score'] for res in results]\n",
    "    plt.plot(f1_scores, label='F1-Score')\n",
    "\n",
    "    # AUC\n",
    "    auc_scores = [res['roc_auc'] for res in results]\n",
    "    plt.plot(auc_scores, label='ROC AUC')\n",
    "\n",
    "    plt.xlabel(\"Experiment Index\")\n",
    "    plt.ylabel(\"Metrics\")\n",
    "    plt.title(\"Model Performance Metrics\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"model_performance.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Run training\n",
    "results = train_and_evaluate()\n",
    "plot_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Set up dataset and transformations\n",
    "data_dir = 'skinType'  # Replace with your dataset path\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images (ImageNet mean & std)\n",
    "])\n",
    "\n",
    "# Step 2: Load dataset using ImageFolder\n",
    "dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Step 3: Split dataset into training, validation, and test sets\n",
    "total_images = len(dataset)\n",
    "train_size = int(0.7 * total_images)\n",
    "val_size = int(0.2 * total_images)\n",
    "test_size = total_images - train_size - val_size\n",
    "train_indices, test_val_indices = train_test_split(range(total_images), test_size=(val_size + test_size), random_state=42)\n",
    "val_indices, test_indices = train_test_split(test_val_indices, test_size=(test_size / (val_size + test_size)), random_state=42)\n",
    "\n",
    "# Create subset datasets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Step 4: Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 5: Define ViT and GAN model (using transformers encoder-decoder)\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViT, self).__init__()\n",
    "        self.vit = torchvision.models.vit_b_16(pretrained=True)  # Using pre-trained ViT model\n",
    "        self.vit.heads = nn.Linear(self.vit.heads.in_features, num_classes)  # Modify final layer to match number of classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.vit(x)\n",
    "\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GAN, self).__init__()\n",
    "        # Placeholder GAN setup for the sake of illustration\n",
    "        # In practice, GAN is more complex involving both generator and discriminator\n",
    "        self.generator = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "# Use ViT or GAN based on requirement\n",
    "model = ViT(num_classes=len(dataset.classes))  # or GAN(num_classes=len(dataset.classes))\n",
    "\n",
    "# Step 6: Set device and move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Step 7: Define optimizers and loss function\n",
    "optimizers = [\n",
    "    torch.optim.Adam(model.parameters(), lr=0.1),\n",
    "    torch.optim.Adam(model.parameters(), lr=0.01),\n",
    "    torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "    torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Using multiclass CrossEntropyLoss\n",
    "\n",
    "# Step 8: Training loop\n",
    "epochs = 3  # Number of epochs\n",
    "\n",
    "# Store metrics for plotting\n",
    "all_metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': [],\n",
    "    'roc_auc': [],\n",
    "    'error': [],\n",
    "    'rmse': []\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    loop = tqdm(train_loader, leave=True)  # Use tqdm for progress bar\n",
    "\n",
    "    for step, (images, labels) in enumerate(loop):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        # Get predictions\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Collect metrics for evaluation\n",
    "        acc = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
    "        precision = precision_score(labels.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        recall = recall_score(labels.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        f1 = f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "\n",
    "        # Collect results for plotting and metrics\n",
    "        all_metrics['accuracy'].append(acc)\n",
    "        all_metrics['precision'].append(precision)\n",
    "        all_metrics['recall'].append(recall)\n",
    "        all_metrics['f1_score'].append(f1)\n",
    "\n",
    "        # Print loss and metrics every 10 steps\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Step {step}, Loss: {loss.item()}, Accuracy: {acc}, Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "\n",
    "    # Step 9: Evaluate the model on the validation set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    val_precision = precision_score(val_labels, val_preds, average='weighted')\n",
    "    val_recall = recall_score(val_labels, val_preds, average='weighted')\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "    print(f\"Validation Accuracy: {val_acc}, Precision: {val_precision}, Recall: {val_recall}, F1: {val_f1}\")\n",
    "\n",
    "# Step 10: Evaluate the model on the test set\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "# Calculate test metrics\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "test_precision = precision_score(test_labels, test_preds, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_preds, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc}, Precision: {test_precision}, Recall: {test_recall}, F1: {test_f1}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(all_metrics['accuracy'], label='Accuracy')\n",
    "plt.plot(all_metrics['precision'], label='Precision')\n",
    "plt.plot(all_metrics['recall'], label='Recall')\n",
    "plt.plot(all_metrics['f1_score'], label='F1 Score')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.legend()\n",
    "plt.title('Model Performance over Time')\n",
    "plt.show()\n",
    "\n",
    "# Save the model and results\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "# Example Discriminator and Generator Models\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Initialize models\n",
    "input_dim = 100  # Latent space\n",
    "output_dim = 784  # Flattened 28x28 image (for example)\n",
    "generator = Generator(input_dim, output_dim)\n",
    "discriminator = Discriminator(output_dim)\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 3\n",
    "batch_sizes = [4, 8, 16, 32, 64]\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "optimizers = [optim.Adam(generator.parameters(), lr=lr) for lr in learning_rates]  # example for Adam optimizer\n",
    "\n",
    "# Data and labels (example)\n",
    "real_labels = torch.ones(4, 1)  # Batch size 4, for example\n",
    "fake_labels = torch.zeros(4, 1)\n",
    "\n",
    "# Random input noise for the generator\n",
    "z = torch.randn(4, input_dim)\n",
    "\n",
    "# Training loop\n",
    "results = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        for optimizer in optimizers:\n",
    "            optimizer.zero_grad()  # Zero gradients before the backward pass\n",
    "            fake_images = generator(z)\n",
    "            output = discriminator(fake_images)\n",
    "\n",
    "            # Calculate Generator loss\n",
    "            loss_g = criterion(output, real_labels)  # Want discriminator to believe fake images are real\n",
    "            \n",
    "            # Backward pass for generator\n",
    "            torch.autograd.set_detect_anomaly(True)  # Enable anomaly detection\n",
    "            loss_g.backward()  # Calculate gradients\n",
    "            optimizer.step()  # Update the generator parameters\n",
    "            \n",
    "            # Evaluate the model performance (for this example)\n",
    "            output_probs = output.detach().numpy()  # Detach to move to numpy for metrics\n",
    "            \n",
    "            # Metrics Calculation\n",
    "            accuracy = accuracy_score(real_labels.numpy(), np.round(output_probs))\n",
    "            precision = precision_score(real_labels.numpy(), np.round(output_probs))\n",
    "            recall = recall_score(real_labels.numpy(), np.round(output_probs))\n",
    "            f1 = f1_score(real_labels.numpy(), np.round(output_probs))\n",
    "            auc = roc_auc_score(real_labels.numpy(), output_probs)\n",
    "            \n",
    "            fpr, tpr, _ = roc_curve(real_labels.numpy(), output_probs)\n",
    "            plt.plot(fpr, tpr, label=f\"LR={optimizer.param_groups[0]['lr']}, Batch={batch_size}\")\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"epoch\": epoch+1,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "                \"loss\": loss_g.item(),\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1_score\": f1,\n",
    "                \"auc\": auc\n",
    "            })\n",
    "            \n",
    "            # Show results every 10 steps (for simplicity, we will use batch_size as a proxy for steps here)\n",
    "            if batch_size % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Batch Size {batch_size}, Loss: {loss_g.item():.4f}, \"\n",
    "                      f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, \"\n",
    "                      f\"F1-Score: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Save plot for ROC curves after each epoch\n",
    "    plt.title(f\"ROC Curves for Epoch {epoch+1}\")\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(f\"roc_epoch_{epoch+1}.png\")\n",
    "    plt.clf()  # Clear the figure for the next epoch\n",
    "\n",
    "# Save results to a file\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"training_results.csv\", index=False)\n",
    "\n",
    "# You can also save the models\n",
    "torch.save(generator.state_dict(), \"generator_model.pth\")\n",
    "torch.save(discriminator.state_dict(), \"discriminator_model.pth\")\n",
    "\n",
    "print(\"Training complete! Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
