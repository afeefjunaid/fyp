{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Noisy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_exts = ['jpg', 'jpeg', 'png', 'bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "\n",
    "data_dir = '../Preprocessing/Processed_Images'\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(image_path)    # print the path of the image with unknown extension\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image:\" .format(image_path))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [16,32]\n",
    "for size in batch_size:\n",
    "   data = tf.keras.utils.image_dataset_from_directory('../Preprocessing/Processed_Images', batch_size=size, image_size=(256, 256), shuffle=True) #Data pipeline\n",
    "\n",
    "class_names = data.class_names #get the class names\n",
    "print(class_names)\n",
    "\n",
    "data_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "\n",
    "batch = data_iterator.next() #get the next batch of data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape # shape of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1] # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "rows = 4\n",
    "cols = 8\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20, 12))\n",
    "fig.suptitle('Sample Images with Class Labels', fontsize=16)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display images in grid\n",
    "for idx, (image, label) in enumerate(zip(batch[0][:32], batch[1][:32])):\n",
    "    # Get class name from label index\n",
    "    class_name = class_names[label]\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx].imshow(image.astype(\"uint8\"))\n",
    "    axes[idx].set_title(f'{class_name}', fontsize=8)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Add color-coded legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=f'C{i}', markersize=10, \n",
    "                             label=name) for i, name in enumerate(class_names)]\n",
    "fig.legend(handles=legend_elements, loc='center right')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)  # Make room for legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y : ((x/255),y)) #normalizing the data  \n",
    "scaled_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "batch = scaled_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].max() #max value in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.7) #70% of the data for training\n",
    "val_size = int(len(data) * 0.2) #20% of the data for validation\n",
    "test_size = int(len(data) * 0.1) #10% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size) #take the first 70% of the data for training\n",
    "val = data.skip(train_size).take(val_size) #skip the first 70% and take the next 20% for validation\n",
    "test = data.skip(train_size + val_size).take(test_size) #skip the first 90% and take the next 10% for testing\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomTranslation, RandomContrast, RandomCrop\n",
    "# filter size = 3x3\n",
    "# input shape = 256x256x3\n",
    "# stride = 1\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = batch[0].shape[0]\n",
    "model = Sequential() #initialize the model\n",
    "\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),         # Flip images both horizontally and vertically\n",
    "    RandomRotation(0.4),                           # Rotate images up to 40% in both directions\n",
    "    RandomZoom(height_factor=(-0.2, 0.2),          # Random zoom in/out\n",
    "               width_factor=(-0.2, 0.2)),\n",
    "    RandomTranslation(height_factor=0.2,           # Translate images up to 20% in height\n",
    "                      width_factor=0.2),           # Translate images up to 20% in width\n",
    "    RandomContrast(0.2),                           # Adjust contrast randomly\n",
    "    RandomCrop(IMAGE_SIZE - 20, IMAGE_SIZE - 20),  # Crop random parts of the image\n",
    "    tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE)  # Resize back to target size\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what is the expected dimension order for channel\n",
    "from tensorflow.keras import backend as k\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "batch_input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "chanDim = -1\n",
    "if k.image_data_format() == \"channels_first\":\n",
    "    input_shape = (CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    batch_input_shape = (BATCH_SIZE, CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    chanDim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "model_dir = '../saved_models'\n",
    "log_dir = os.path.join(model_dir, 'logs')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(model_dir, 'best_model.keras'),\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "final_model_path = os.path.join(model_dir, 'final_model.keras')\n",
    "model.save(final_model_path)\n",
    "print(f\"Model saved to {final_model_path}\")\n",
    "from matplotlib import pyplot as plt\n",
    "rows = 4\n",
    "cols = 8\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20, 12))\n",
    "fig.suptitle('Sample Images with Class Labels', fontsize=16)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display images in grid\n",
    "for idx, (image, label) in enumerate(zip(batch[0][:32], batch[1][:32])):\n",
    "    # Get class name from label index\n",
    "    class_name = class_names[label]\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx].imshow(image.astype(\"uint8\"))\n",
    "    axes[idx].set_title(f'{class_name}', fontsize=8)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Add color-coded legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=f'C{i}', markersize=10, \n",
    "                             label=name) for i, name in enumerate(class_names)]\n",
    "fig.legend(handles=legend_elements, loc='center right')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)  # Make room for legend\n",
    "plt.show()\n",
    "\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "train = data.take(train_size) #take the first 70% of the data for training\n",
    "val = data.skip(train_size).take(val_size) #skip the first 70% and take the next 20% for validation\n",
    "test = data.skip(train_size + val_size).take(test_size) #skip the first 90% and take the next 10% for testing\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "img_exts = ['jpg', 'jpeg', 'png', 'bmp']\n",
    "data_dir = 'skinType'\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(image_path)    # print the path of the image with unknown extension\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image:\" .format(image_path))\n",
    "batch_size = [16,32]\n",
    "for size in batch_size:\n",
    "   data = tf.keras.utils.image_dataset_from_directory('skinType', batch_size=size, image_size=(256, 256), shuffle=True) #Data pipeline\n",
    "\n",
    "class_names = data.class_names #get the class names\n",
    "print(class_names)\n",
    "\n",
    "data_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "\n",
    "batch = data_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].shape # shape of the batch\n",
    "       \n",
    "batch[1] # labels\n",
    "\n",
    "data = data.map(lambda x,y : ((x/255),y)) #normalizing the data  \n",
    "scaled_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "batch = scaled_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].max() #max value in the batch\n",
    "\n",
    "len(data)\n",
    "\n",
    "train_size = int(len(data) * 0.7) #70% of the data for training\n",
    "val_size = int(len(data) * 0.2) #20% of the data for validation\n",
    "test_size = int(len(data) * 0.1) #10% of the data for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from vit_pytorch import ViT\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lamb import Lamb\n",
    "from torch.optim import AdamW\n",
    "import timm \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#unprocessed Data\n",
    "# dataset_path = '../skinType' \n",
    "\n",
    "#preprocessed Data\n",
    "dataset_path = '../Preprocessing/Processed_Images'\n",
    "#dataset_path=\"../skintypepatches 128x128\"\n",
    "#_FaceCrops_256' \n",
    "\n",
    "# Define hyperparameters\n",
    "batch_sizes = [ 8, 32,64]\n",
    "learning_rates =[0.01, 0.001]\n",
    "optimizers_list = ['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "\n",
    "num_classes = 3  # Dry, Normal, Oily skin types\n",
    "#class_names = ['oily', 'dry', 'normal']\n",
    "steps_per_epoch = 20 \n",
    "total_epochs=500\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "# Load Dataset\n",
    "transform = transforms.Compose([\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(10),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std)\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std)\n",
    "# ])\n",
    "# Dataset Path\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.20 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "#val_dataset.dataset.transform = val_transform\n",
    "print(f\"train size {train_size}\")\n",
    "print(f\"Val size {val_size}\")\n",
    "print(f\"Test Size {test_size}\")\n",
    "\n",
    "# print(f\"train Dataset {train_dataset}\")\n",
    "# print(f\"Val Dataset {val_dataset}\")\n",
    "# print(f\"Test Dataset {test_dataset}\")\n",
    "\n",
    "# Function to initialize the model\n",
    "# def create_vit_model():    \n",
    "#     model = ViT(\n",
    "#         image_size=128,\n",
    "#         patch_size=16,\n",
    "#         num_classes=num_classes,  \n",
    "#         dim=512,                      \n",
    "#         heads=8,  \n",
    "#         depth=8,              \n",
    "#         mlp_dim=512,          \n",
    "#         dropout=0.4,           \n",
    "#         emb_dropout=0.4        \n",
    "#     )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# Optimizer choices\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return optim.AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    y_true, y_pred = [], []\n",
    "    all_probs = []\n",
    "\n",
    "    for inputs, labels in tqdm(loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.detach().cpu().numpy())\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    try:\n",
    "        unique_classes = np.unique(all_labels)\n",
    "        if len(unique_classes) == num_classes:\n",
    "            roc_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr', average='weighted')\n",
    "        else:\n",
    "            roc_auc = None\n",
    "    except ValueError:\n",
    "        roc_auc = None \n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "\n",
    "    return running_loss / len(loader), accuracy, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Validation and Test Function\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    all_probs = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        unique_classes = np.unique(all_labels)\n",
    "        if len(unique_classes) == num_classes:\n",
    "            roc_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr', average='weighted')\n",
    "        else:\n",
    "            print(\"Warning: Not all classes are present in the evaluation set. Skipping ROC-AUC calculation.\")\n",
    "            roc_auc = None\n",
    "    except ValueError:\n",
    "        roc_auc = None  \n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "    \n",
    "    return running_loss / len(loader), accuracy, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "# Main training loop\n",
    "def train_and_evaluate(batch_size, lr, optimizer_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "    model.to(device)\n",
    "    optimizer = get_optimizer(optimizer_name, model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    # Training\n",
    "    for epoch in range(100,total_epochs,20):\n",
    "        # print(\"\\n\\n-------------------------Checking Weights in Each Iteration----------------------------\")\n",
    "        # print(\"Initial Weights:\")\n",
    "        # print_weights(model)\n",
    "        # print(\"\\n\\n-------------------------Checking Weights in Each Iteration-----------------------------\")\n",
    "  \n",
    "        train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse= evaluate_model(model, val_loader, criterion, device)\n",
    "        test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step()\n",
    "        scheduler.step(val_loss)\n",
    "        print(\"----------Values After Training-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "              f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                   f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                   f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "              f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                    f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                    f\"Val RMSE: {val_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "              f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                    f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "                \n",
    "        \n",
    "       \n",
    "        \n",
    "        #Saving Training data\n",
    "        overall_result = {\n",
    "            'Epoch': epoch + 1,\n",
    "            'Batch Size': batch_size,\n",
    "            'Learning Rate': lr,\n",
    "            'Optimizer': optimizer_name,\n",
    "            \n",
    "            'Train Loss':round(train_loss, 4),\n",
    "            'Test Loss':round(test_loss, 4),\n",
    "            'Val Loss':round(val_loss, 4),\n",
    "            \n",
    "            'Train Acc': round(train_acc, 4),\n",
    "            'Test Acc': round(test_acc, 4),\n",
    "            'Val Acc': round(val_acc, 4),\n",
    "            \n",
    "            \n",
    "            'Train Precision': round(train_precision, 4),\n",
    "            'Test Precision': round(test_precision, 4),\n",
    "            'Val Precision': round(val_precision, 4),\n",
    "            \n",
    "            'Train Recall': round(train_recall, 4),\n",
    "            'Test Recall': round(test_recall, 4),\n",
    "            'Val Recall': round(val_recall, 4),\n",
    "            \n",
    "            'Train F1 Score': round(train_f1, 4),\n",
    "            'Test F1 Score': round(test_f1, 4),\n",
    "            'Val F1 Score': round(val_f1, 4),\n",
    "            \n",
    "            'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "            'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "            'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "            \n",
    "            'Train RMSE': round(train_rmse, 4),\n",
    "            'Test RMSE': round(test_rmse, 4),\n",
    "            'Val RMSE': round(val_rmse, 4)\n",
    "        }\n",
    "        \n",
    "        # Append to CSV\n",
    "        overall_result_file = 'pretrained_overall_result.csv'\n",
    "        \n",
    "        if not os.path.isfile(overall_result_file):\n",
    "            pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)        \n",
    "        else:\n",
    "            pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "            \n",
    "    # Save the trained model\n",
    "    os.makedirs('../saved_models', exist_ok=True)\n",
    "    model_save_path = f\"../saved_models/vit_model_bs{batch_size}_lr{lr}_optimizer{optimizer_name}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # # Convert results into DataFrame\n",
    "    df_results = pd.read_csv('pretrained_overall_result.csv')\n",
    "\n",
    "    # Reshape the dataframe to long format for seaborn\n",
    "    df_long = pd.melt(df_results, id_vars=['Epoch'], var_name='Metric', value_name='Value')\n",
    "\n",
    "    # Optional: Drop rows with NaN values in the Value column (if any)\n",
    "    df_long = df_long.dropna(subset=['Value'])\n",
    "\n",
    "    # Set up the plots with a style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Plot Loss (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Loss', 'Test Loss', 'Val Loss'])],x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Accuracy (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Acc', 'Test Acc', 'Val Acc'])],\n",
    "                x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Precision (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Precision', 'Test Precision', 'Val Precision'])],x='Epoch', y='Value', \n",
    "                 hue='Metric')\n",
    "    plt.title('Precision Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Recall (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Recall', 'Test Recall', 'Val Recall'])],x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('Recall Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot F1 Score (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train F1 Score', 'Test F1 Score', 'Val F1 Score'])],\n",
    "                x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('F1 Score Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC AUC (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train ROC AUC', 'Test ROC AUC', 'Val ROC AUC'])],\n",
    "                x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('ROC AUC Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot RMSE (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train RMSE', 'Test RMSE', 'Val RMSE'])],\n",
    "                x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('RMSE Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # return test_acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "                #test_metrics = \n",
    "                train_and_evaluate(batch_size, lr, optimizer_name)\n",
    "                # print(f\"Final Test Metrics with Batch Size {batch_size}, LR {lr}, Optimizer {optimizer_name}: {test_metrics}\")\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Model With Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb\n",
    "import clip\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [8]\n",
    "learning_rates = [0.01, 0.001]\n",
    "optimizers_list = ['LAMB', 'AdamW']\n",
    "\n",
    "# batch_sizes = [8, 32, 64]\n",
    "# learning_rates = [0.01, 0.001]\n",
    "# optimizers_list = ['LAMB', 'AdamW']\n",
    "\n",
    "total_epochs = 250\n",
    "start=1\n",
    "step=1\n",
    "\n",
    "# Load CLIP model and preprocessing\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "data_dir = r\"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "# Data Splitting\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "print(f\"train size {train_size}\")\n",
    "print(f\"Val size {val_size}\")\n",
    "print(f\"Test Size {test_size}\")\n",
    "\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return optim.AdamW(model_params, lr=lr,weight_decay=weight_decay)\n",
    "    elif optimizer_name=='LAMB':\n",
    "        return Lamb(model_params, lr=lr,weight_decay=weight_decay)\n",
    "    \n",
    "    \n",
    "# Freeze CLIP vision encoder\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Model definition\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "model = CLIPSkinClassifier(clip_model, num_classes=3).to(device).float()\n",
    "\n",
    "\n",
    "\n",
    "# Metric helper\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Train loop\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Eval loop\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Training loop with logging\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            # Loss and optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = Lamb(model.parameters(), lr=lr)\n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                # Save results to CSV\n",
    "                overall_result = {\n",
    "                    'Epoch': epoch + 1,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'sample result (250).csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "\n",
    "            # Save model\n",
    "            os.makedirs('../saved_models', exist_ok=True)\n",
    "            model_save_path = f\"../saved_models/vit_model_bs{batch_size}_lr{lr}_optimizer{optimizer_name}.pth\"\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Model With Clipping (ahmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  \n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from pytorch_lamb import Lamb\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "batch_sizes = [32,64]\n",
    "learning_rates = [0.1,0.01,0.001,0.0001,0.00001]\n",
    "optimizers_list = ['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "num_classes=3\n",
    "total_epochs = 501\n",
    "start=100\n",
    "step=5\n",
    "\n",
    "\n",
    "\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            model = CLIPSkinClassifier(clip_model, num_classes=num_classes).to(device).float()\n",
    "            \n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = get_optimizer(optimizer_name,model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                \n",
    "                \n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc if train_roc_auc is not None else 'N/A'}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc if train_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                \n",
    "                \n",
    "                overall_result = {\n",
    "                    'Epoch': epoch,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'ahmed final testing.csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df_results = pd.read_csv('reduced_200_pretrained_overall_result.csv')\n",
    "\n",
    "# Reshape the dataframe to long format for seaborn\n",
    "df_long = pd.melt(df_results, id_vars=['Epoch'], var_name='Metric', value_name='Value')\n",
    "\n",
    "# Optional: Drop rows with NaN values in the Value column (if any)\n",
    "df_long = df_long.dropna(subset=['Value'])\n",
    "\n",
    "# Set up the plots with a style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Plot Loss (Train, Test, Val)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Loss', 'Test Loss', 'Val Loss'])],\n",
    "             x='Epoch', y='Value', hue='Metric')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(title='Metric')\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy (Train, Test, Val)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Acc', 'Test Acc', 'Val Acc'])],\n",
    "             x='Epoch', y='Value', hue='Metric')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(title='Metric')\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision (Train, Test, Val)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Precision', 'Test Precision', 'Val Precision'])],\n",
    "             x='Epoch', y='Value', hue='Metric')\n",
    "plt.title('Precision Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(title='Metric')\n",
    "plt.show()\n",
    "\n",
    "# Plot Recall (Train, Test, Val)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Recall', 'Test Recall', 'Val Recall'])],\n",
    "             x='Epoch', y='Value', hue='Metric')\n",
    "plt.title('Recall Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend(title='Metric')\n",
    "plt.show()\n",
    "\n",
    "# Plot F1 Score (Train, Test, Val)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_long[df_long['Metric'].isin(['Train F1 Score', 'Test F1 Score', 'Val F1 Score'])],\n",
    "             x='Epoch', y='Value', hue='Metric')\n",
    "plt.title('F1 Score Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend(title='Metric')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC AUC (Train, Test, Val)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_long[df_long['Metric'].isin(['Train ROC AUC', 'Test ROC AUC', 'Val ROC AUC'])],\n",
    "             x='Epoch', y='Value', hue='Metric')\n",
    "plt.title('ROC AUC Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend(title='Metric')\n",
    "plt.show()\n",
    "\n",
    "# Plot RMSE (Train, Test, Val)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_long[df_long['Metric'].isin(['Train RMSE', 'Test RMSE', 'Val RMSE'])],\n",
    "             x='Epoch', y='Value', hue='Metric')\n",
    "plt.title('RMSE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(title='Metric')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akhati report (12 vlaues in each graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import os\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('reduced_200_pretrained_overall_result.csv')\n",
    "\n",
    "# Set correct column names\n",
    "lr_col = 'Learning Rate'\n",
    "bs_col = 'Batch Size'\n",
    "opt_col = 'Optimizer'\n",
    "epoch_col = 'Epoch'\n",
    "\n",
    "# Metrics to plot\n",
    "metrics = [ \n",
    "    'Train Loss', 'Test Loss', 'Val Loss',\n",
    "    'Train Acc', 'Test Acc', 'Val Acc',\n",
    "    'Train Precision', 'Test Precision', 'Val Precision',\n",
    "    'Train Recall', 'Test Recall', 'Val Recall',\n",
    "    'Train F1 Score', 'Test F1 Score', 'Val F1 Score',\n",
    "    'Train ROC AUC', 'Test ROC AUC', 'Val ROC AUC',\n",
    "    'Train RMSE', 'Test RMSE', 'Val RMSE'\n",
    "]\n",
    "\n",
    "# Create unique configuration name\n",
    "df['config'] = df[lr_col].astype(str) + '_lr_' + \\\n",
    "               df[bs_col].astype(str) + '_bs_' + \\\n",
    "               df[opt_col]\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Create a directory to save images\n",
    "image_dir = \"metric_plots\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# Create Word document\n",
    "doc = Document()\n",
    "doc.add_heading('Training Metrics Report', 0)\n",
    "\n",
    "# Generate plots and add to document\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for config_name, group in df.groupby('config'):\n",
    "        plt.plot(group[epoch_col], group[metric], label=config_name)\n",
    "\n",
    "    plt.title(metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend(title='Config', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot as image\n",
    "    image_path = os.path.join(image_dir, f\"{metric.replace(' ', '_')}.png\")\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Add title and image to Word doc\n",
    "    doc.add_heading(metric, level=1)\n",
    "    doc.add_picture(image_path, width=Inches(6.5))  # Adjust width if needed\n",
    "\n",
    "# Save the Word document\n",
    "doc.save('Reduced 200 Images Training Metrics Report.docx')\n",
    "print(\"Word document 'Training_Metrics_Report.docx' created with all plots.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alag alag report based on (learning rate, batch size, optimizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"reduced_200_pretrained_overall_result.csv\")\n",
    "\n",
    "# Combine hyperparameters into a config string for reference (not used in graph)\n",
    "df['Config'] = df.apply(lambda row: f\"LR={row['Learning Rate']} | BS={row['Batch Size']} | Opt={row['Optimizer']}\", axis=1)\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# List of metrics to visualize\n",
    "metrics = [\n",
    "    'Train Loss', 'Test Loss', 'Val Loss',\n",
    "    'Train Acc', 'Test Acc', 'Val Acc',\n",
    "    'Train Precision', 'Test Precision', 'Val Precision',\n",
    "    'Train Recall', 'Test Recall', 'Val Recall',\n",
    "    'Train F1 Score', 'Test F1 Score', 'Val F1 Score',\n",
    "    'Train ROC AUC', 'Test ROC AUC', 'Val ROC AUC',\n",
    "    'Train RMSE', 'Test RMSE', 'Val RMSE'\n",
    "]\n",
    "\n",
    "# Create a folder for images\n",
    "img_folder = \"metric_images\"\n",
    "os.makedirs(img_folder, exist_ok=True)\n",
    "\n",
    "# Create Word document\n",
    "doc = Document()\n",
    "doc.add_heading(\"Model Evaluation Metrics Report\", 0)\n",
    "\n",
    "# Loop over each metric, create and save plot, insert into doc\n",
    "for metric in metrics:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Plot by Learning Rate\n",
    "    sns.lineplot(data=df, x='Epoch', y=metric, hue='Learning Rate', marker='o', ax=axes[0])\n",
    "    axes[0].set_title(f\"{metric} vs Epoch (Learning Rate)\")\n",
    "    axes[0].legend(title=\"LR\", fontsize=7)\n",
    "\n",
    "    # Plot by Batch Size\n",
    "    sns.lineplot(data=df, x='Epoch', y=metric, hue='Batch Size', marker='o', ax=axes[1])\n",
    "    axes[1].set_title(f\"{metric} vs Epoch (Batch Size)\")\n",
    "    axes[1].legend(title=\"BS\", fontsize=7)\n",
    "\n",
    "    # Plot by Optimizer\n",
    "    sns.lineplot(data=df, x='Epoch', y=metric, hue='Optimizer', marker='o', ax=axes[2])\n",
    "    axes[2].set_title(f\"{metric} vs Epoch (Optimizer)\")\n",
    "    axes[2].legend(title=\"Opt\", fontsize=7)\n",
    "\n",
    "    # Save figure\n",
    "    image_path = os.path.join(img_folder, f\"{metric.replace(' ', '_')}.png\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(image_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Add to Word doc\n",
    "    doc.add_heading(metric, level=1)\n",
    "    doc.add_picture(image_path, width=Inches(6.5))  # Use full width, fits well\n",
    "\n",
    "# Save final document\n",
    "doc.save(\"Reduced 200 Images Metric Evaluation Report.docx\")\n",
    "print(\"✅ All metric graphs saved and Word document generated as 'Metric_Evaluation_Report.docx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb\n",
    "import clip\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [8]\n",
    "learning_rates = [0.001]\n",
    "optimizers_list = ['LAMB', 'AdamW']\n",
    "total_epochs = 500\n",
    "start=100\n",
    "step=20\n",
    "\n",
    "# Load CLIP model and preprocessing\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "data_dir = r\"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "# Data Splitting\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"train size {train_size}\")\n",
    "print(f\"Val size {val_size}\")\n",
    "print(f\"Test Size {test_size}\")\n",
    "\n",
    "\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return optim.AdamW(model_params, lr=lr,weight_decay=weight_decay)\n",
    "    elif optimizer_name=='LAMB':\n",
    "        return Lamb(model_params, lr=lr,weight_decay=weight_decay)\n",
    "    \n",
    "    \n",
    "# Freeze CLIP vision encoder\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Model definition\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "model = CLIPSkinClassifier(clip_model, num_classes=3).to(device).float()\n",
    "\n",
    "\n",
    "\n",
    "# Metric helper\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Train loop\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Eval loop\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Training loop with logging\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            # Loss and optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = Lamb(model.parameters(), lr=lr)\n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                # Save results to CSV\n",
    "                overall_result = {\n",
    "                    'Epoch': epoch + 1,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'sample result (250).csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "\n",
    "            # Save model\n",
    "            os.makedirs('../saved_models', exist_ok=True)\n",
    "            model_save_path = f\"../saved_models/vit_model_bs{batch_size}_lr{lr}_optimizer{optimizer_name}.pth\"\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  # You may need to install this via pip install pytorch-optimizer\n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "lr = 0.0001\n",
    "optimizer_name = \"AdamW\"\n",
    "total_epochs = 501\n",
    "start=1\n",
    "step=1\n",
    "\n",
    "# Load CLIP model and preprocessing\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "data_dir = \"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "# Data Splitting\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Freeze CLIP vision encoder\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Model definition\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "model = CLIPSkinClassifier(clip_model, num_classes=3).to(device).float()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Lamb(model.parameters(), lr=lr)\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "# Metric helper\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Train loop\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Eval loop\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Training loop with logging\n",
    "for epoch in range(start,total_epochs,step):\n",
    "    train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "    test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "    print(\"----------Values After Training-----------\")\n",
    "    print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "          f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "               f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "               f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "    print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "    print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "          f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "    print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "    print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "          f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    overall_result = {\n",
    "        'Epoch': epoch + 1,\n",
    "        'Batch Size': batch_size,\n",
    "        'Learning Rate': lr,\n",
    "        'Optimizer': optimizer_name,\n",
    "\n",
    "        'Train Loss': round(train_loss, 4),\n",
    "        'Test Loss': round(test_loss, 4),\n",
    "        'Val Loss': round(val_loss, 4),\n",
    "\n",
    "        'Train Acc': round(train_acc, 4),\n",
    "        'Test Acc': round(test_acc, 4),\n",
    "        'Val Acc': round(val_acc, 4),\n",
    "\n",
    "        'Train Precision': round(train_precision, 4),\n",
    "        'Test Precision': round(test_precision, 4),\n",
    "        'Val Precision': round(val_precision, 4),\n",
    "\n",
    "        'Train Recall': round(train_recall, 4),\n",
    "        'Test Recall': round(test_recall, 4),\n",
    "        'Val Recall': round(val_recall, 4),\n",
    "\n",
    "        'Train F1 Score': round(train_f1, 4),\n",
    "        'Test F1 Score': round(test_f1, 4),\n",
    "        'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "        'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "        'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "        'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "        'Train RMSE': round(train_rmse, 4),\n",
    "        'Test RMSE': round(test_rmse, 4),\n",
    "        'Val RMSE': round(val_rmse, 4)\n",
    "    }\n",
    "\n",
    "    overall_result_file = 'test with shuffle.csv'\n",
    "    if not os.path.isfile(overall_result_file):\n",
    "        pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "    else:\n",
    "        pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  \n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from pytorch_lamb import Lamb\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "batch_sizes = [8,16,32,64]\n",
    "learning_rates = [0.1,0.01,0.001,0.0001,0.00001]\n",
    "optimizers_list = ['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "num_classes=3\n",
    "total_epochs = 2\n",
    "start=1\n",
    "step=1\n",
    "\n",
    "\n",
    "\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            model = CLIPSkinClassifier(clip_model, num_classes=num_classes).to(device).float()\n",
    "            \n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = get_optimizer(optimizer_name,model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                \n",
    "                \n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc if train_roc_auc is not None else 'N/A'}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc if train_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                \n",
    "                \n",
    "                overall_result = {\n",
    "                    'Epoch': epoch + 1,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'final testing.csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Classes: ['dry', 'normal', 'oily']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:11<00:00, 34.00it/s]\n",
      "100%|██████████| 691/691 [00:20<00:00, 34.15it/s]\n",
      "100%|██████████| 346/346 [00:10<00:00, 34.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [101/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 1.0787, Train Acc: 0.4024, Train Precision: 0.4019, Train Recall: 0.4023, Train  F1: 0.4010,Train ROC AUC: 0.5838344516100681, Train RMSE: 1.1066\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [101/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0658, Val Acc: 0.4196, Val Precision: 0.4181, Val Recall: 0.4182, Val F1: 0.4141, Val ROC AUC: 0.6074109252909863, Val RMSE: 1.0466\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [101/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0714, Test Acc: 0.4225, Test Precision: 0.4265, Test Recall: 0.4234, Test F1: 0.4209, Test ROC AUC: 0.5990561889870084, Test RMSE: 1.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:11<00:00, 34.00it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 35.93it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 36.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [106/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 1.0558, Train Acc: 0.4406, Train Precision: 0.4402, Train Recall: 0.4405, Train  F1: 0.4400,Train ROC AUC: 0.6237732458456786, Train RMSE: 1.0654\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [106/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0539, Val Acc: 0.4449, Val Precision: 0.4478, Val Recall: 0.4443, Val F1: 0.4334, Val ROC AUC: 0.629861836281402, Val RMSE: 1.0467\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [106/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0606, Test Acc: 0.4341, Test Precision: 0.4411, Test Recall: 0.4356, Test F1: 0.4273, Test ROC AUC: 0.620873488509803, Test RMSE: 1.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:08<00:00, 35.22it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 36.00it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 34.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [111/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 1.0405, Train Acc: 0.4570, Train Precision: 0.4568, Train Recall: 0.4569, Train  F1: 0.4565,Train ROC AUC: 0.6450663841834798, Train RMSE: 1.0502\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [111/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0479, Val Acc: 0.4460, Val Precision: 0.4534, Val Recall: 0.4472, Val F1: 0.4436, Val ROC AUC: 0.6377646522820677, Val RMSE: 1.0829\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [111/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0545, Test Acc: 0.4308, Test Precision: 0.4342, Test Recall: 0.4295, Test F1: 0.4249, Test ROC AUC: 0.6275480517528298, Test RMSE: 1.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:08<00:00, 35.29it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 35.55it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 35.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [116/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 1.0286, Train Acc: 0.4749, Train Precision: 0.4749, Train Recall: 0.4748, Train  F1: 0.4747,Train ROC AUC: 0.659179571566906, Train RMSE: 1.0321\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [116/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0413, Val Acc: 0.4500, Val Precision: 0.4572, Val Recall: 0.4514, Val F1: 0.4467, Val ROC AUC: 0.6445294518047565, Val RMSE: 1.0778\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [116/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0441, Test Acc: 0.4537, Test Precision: 0.4606, Test Recall: 0.4523, Test F1: 0.4472, Test ROC AUC: 0.6414784783078736, Test RMSE: 1.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:08<00:00, 35.38it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 35.72it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 35.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [121/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 1.0142, Train Acc: 0.4877, Train Precision: 0.4876, Train Recall: 0.4876, Train  F1: 0.4875,Train ROC AUC: 0.6739528897597875, Train RMSE: 1.0156\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [121/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0357, Val Acc: 0.4681, Val Precision: 0.4738, Val Recall: 0.4677, Val F1: 0.4658, Val ROC AUC: 0.6535294885914728, Val RMSE: 1.0242\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [121/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0427, Test Acc: 0.4587, Test Precision: 0.4633, Test Recall: 0.4581, Test F1: 0.4566, Test ROC AUC: 0.6462411909446262, Test RMSE: 1.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:08<00:00, 35.34it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 35.97it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 35.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [126/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 1.0028, Train Acc: 0.4983, Train Precision: 0.4984, Train Recall: 0.4983, Train  F1: 0.4983,Train ROC AUC: 0.6852842823270997, Train RMSE: 1.0078\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [126/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0287, Val Acc: 0.4660, Val Precision: 0.4729, Val Recall: 0.4670, Val F1: 0.4624, Val ROC AUC: 0.6604477135796313, Val RMSE: 1.0704\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [126/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0376, Test Acc: 0.4573, Test Precision: 0.4609, Test Recall: 0.4570, Test F1: 0.4519, Test ROC AUC: 0.649771127399177, Test RMSE: 1.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:08<00:00, 35.24it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 35.47it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 36.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [131/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.9922, Train Acc: 0.5053, Train Precision: 0.5053, Train Recall: 0.5052, Train  F1: 0.5052,Train ROC AUC: 0.6950174000444328, Train RMSE: 1.0010\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [131/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0193, Val Acc: 0.4756, Val Precision: 0.4794, Val Recall: 0.4765, Val F1: 0.4744, Val ROC AUC: 0.6685032710828359, Val RMSE: 1.0461\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [131/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0271, Test Acc: 0.4631, Test Precision: 0.4646, Test Recall: 0.4621, Test F1: 0.4582, Test ROC AUC: 0.65973847632227, Test RMSE: 1.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:07<00:00, 35.59it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 35.78it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 36.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [136/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.9801, Train Acc: 0.5181, Train Precision: 0.5182, Train Recall: 0.5181, Train  F1: 0.5180,Train ROC AUC: 0.7065111070349621, Train RMSE: 0.9851\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [136/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0180, Val Acc: 0.4873, Val Precision: 0.4889, Val Recall: 0.4862, Val F1: 0.4849, Val ROC AUC: 0.6704292636931418, Val RMSE: 0.9844\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [136/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0214, Test Acc: 0.4888, Test Precision: 0.4924, Test Recall: 0.4892, Test F1: 0.4877, Test ROC AUC: 0.668758895363632, Test RMSE: 0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:07<00:00, 35.56it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 36.15it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [141/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.9650, Train Acc: 0.5292, Train Precision: 0.5292, Train Recall: 0.5291, Train  F1: 0.5291,Train ROC AUC: 0.7183392415808826, Train RMSE: 0.9712\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [141/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0100, Val Acc: 0.4899, Val Precision: 0.4914, Val Recall: 0.4890, Val F1: 0.4881, Val ROC AUC: 0.6769812703998367, Val RMSE: 0.9952\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [141/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0171, Test Acc: 0.4826, Test Precision: 0.4863, Test Recall: 0.4825, Test F1: 0.4820, Test ROC AUC: 0.6698019833715153, Test RMSE: 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:09<00:00, 34.89it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 35.59it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 35.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [146/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.9527, Train Acc: 0.5388, Train Precision: 0.5389, Train Recall: 0.5388, Train  F1: 0.5388,Train ROC AUC: 0.7293922493672799, Train RMSE: 0.9632\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [146/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0053, Val Acc: 0.4969, Val Precision: 0.5015, Val Recall: 0.4971, Val F1: 0.4962, Val ROC AUC: 0.6815373666671078, Val RMSE: 1.0066\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [146/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0118, Test Acc: 0.4924, Test Precision: 0.4963, Test Recall: 0.4914, Test F1: 0.4903, Test ROC AUC: 0.6760470637101433, Test RMSE: 1.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:09<00:00, 34.91it/s]\n",
      "100%|██████████| 691/691 [00:20<00:00, 34.54it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 26.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [151/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.9419, Train Acc: 0.5505, Train Precision: 0.5507, Train Recall: 0.5505, Train  F1: 0.5505,Train ROC AUC: 0.7378994238749611, Train RMSE: 0.9518\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [151/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 1.0076, Val Acc: 0.4897, Val Precision: 0.4961, Val Recall: 0.4902, Val F1: 0.4885, Val ROC AUC: 0.6823407899923192, Val RMSE: 1.0259\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [151/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0164, Test Acc: 0.4848, Test Precision: 0.4895, Test Recall: 0.4835, Test F1: 0.4811, Test ROC AUC: 0.6736399433322525, Test RMSE: 1.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:47<00:00, 22.55it/s]\n",
      "100%|██████████| 691/691 [00:30<00:00, 22.45it/s]\n",
      "100%|██████████| 346/346 [00:15<00:00, 22.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [156/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.9299, Train Acc: 0.5602, Train Precision: 0.5602, Train Recall: 0.5602, Train  F1: 0.5602,Train ROC AUC: 0.7460943836359366, Train RMSE: 0.9320\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [156/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9986, Val Acc: 0.5029, Val Precision: 0.5084, Val Recall: 0.5028, Val F1: 0.5010, Val ROC AUC: 0.6899030825302278, Val RMSE: 0.9957\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [156/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 1.0072, Test Acc: 0.4975, Test Precision: 0.5035, Test Recall: 0.4962, Test F1: 0.4935, Test ROC AUC: 0.6812638514966837, Test RMSE: 0.9956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:40<00:00, 24.03it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 34.85it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 35.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [161/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.9172, Train Acc: 0.5645, Train Precision: 0.5645, Train Recall: 0.5644, Train  F1: 0.5644,Train ROC AUC: 0.7555707561005404, Train RMSE: 0.9301\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [161/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9959, Val Acc: 0.4987, Val Precision: 0.5066, Val Recall: 0.5000, Val F1: 0.4958, Val ROC AUC: 0.6944945627098512, Val RMSE: 1.0337\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [161/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9975, Test Acc: 0.4986, Test Precision: 0.5007, Test Recall: 0.4978, Test F1: 0.4930, Test ROC AUC: 0.6933714407280306, Test RMSE: 1.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:13<00:00, 32.92it/s]\n",
      "100%|██████████| 691/691 [00:26<00:00, 25.70it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [166/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.9048, Train Acc: 0.5784, Train Precision: 0.5783, Train Recall: 0.5783, Train  F1: 0.5783,Train ROC AUC: 0.7649597997491409, Train RMSE: 0.9149\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [166/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9933, Val Acc: 0.5136, Val Precision: 0.5209, Val Recall: 0.5129, Val F1: 0.5116, Val ROC AUC: 0.6945015738952671, Val RMSE: 0.9608\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [166/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9985, Test Acc: 0.5080, Test Precision: 0.5132, Test Recall: 0.5074, Test F1: 0.5058, Test ROC AUC: 0.6894056274624484, Test RMSE: 0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:42<00:00, 23.49it/s]\n",
      "100%|██████████| 691/691 [00:29<00:00, 23.58it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 25.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [171/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.8936, Train Acc: 0.5868, Train Precision: 0.5868, Train Recall: 0.5867, Train  F1: 0.5867,Train ROC AUC: 0.772245049905456, Train RMSE: 0.9058\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [171/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9913, Val Acc: 0.5062, Val Precision: 0.5144, Val Recall: 0.5056, Val F1: 0.5041, Val ROC AUC: 0.6984147099751711, Val RMSE: 0.9725\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [171/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9890, Test Acc: 0.5134, Test Precision: 0.5235, Test Recall: 0.5127, Test F1: 0.5113, Test ROC AUC: 0.7002093754888973, Test RMSE: 0.9642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:46<00:00, 22.68it/s]\n",
      "100%|██████████| 691/691 [00:28<00:00, 23.90it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [176/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.8787, Train Acc: 0.5961, Train Precision: 0.5962, Train Recall: 0.5960, Train  F1: 0.5960,Train ROC AUC: 0.7820584152764138, Train RMSE: 0.8980\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [176/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9769, Val Acc: 0.5235, Val Precision: 0.5247, Val Recall: 0.5230, Val F1: 0.5229, Val ROC AUC: 0.7080069330886989, Val RMSE: 0.9568\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [176/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9757, Test Acc: 0.5243, Test Precision: 0.5268, Test Recall: 0.5241, Test F1: 0.5243, Test ROC AUC: 0.7085752487819915, Test RMSE: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:55<00:00, 20.93it/s]\n",
      "100%|██████████| 691/691 [00:32<00:00, 21.17it/s]\n",
      "100%|██████████| 346/346 [00:16<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [181/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.8680, Train Acc: 0.6038, Train Precision: 0.6038, Train Recall: 0.6038, Train  F1: 0.6038,Train ROC AUC: 0.7885973870793145, Train RMSE: 0.8858\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [181/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9733, Val Acc: 0.5254, Val Precision: 0.5268, Val Recall: 0.5258, Val F1: 0.5253, Val ROC AUC: 0.7113423702599748, Val RMSE: 0.9808\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [181/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9738, Test Acc: 0.5279, Test Precision: 0.5275, Test Recall: 0.5273, Test F1: 0.5264, Test ROC AUC: 0.7095342137790787, Test RMSE: 0.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:19<00:00, 30.48it/s]\n",
      "100%|██████████| 691/691 [00:20<00:00, 33.04it/s]\n",
      "100%|██████████| 346/346 [00:10<00:00, 32.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [186/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.8561, Train Acc: 0.6114, Train Precision: 0.6115, Train Recall: 0.6114, Train  F1: 0.6114,Train ROC AUC: 0.7958249930119715, Train RMSE: 0.8790\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [186/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9677, Val Acc: 0.5270, Val Precision: 0.5278, Val Recall: 0.5272, Val F1: 0.5270, Val ROC AUC: 0.7145802296486664, Val RMSE: 0.9772\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [186/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9699, Test Acc: 0.5210, Test Precision: 0.5212, Test Recall: 0.5204, Test F1: 0.5199, Test ROC AUC: 0.7127879445423685, Test RMSE: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:19<00:00, 30.47it/s]\n",
      "100%|██████████| 691/691 [00:21<00:00, 32.12it/s]\n",
      "100%|██████████| 346/346 [00:10<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [191/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.8401, Train Acc: 0.6228, Train Precision: 0.6227, Train Recall: 0.6227, Train  F1: 0.6226,Train ROC AUC: 0.8052065534646417, Train RMSE: 0.8602\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [191/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9684, Val Acc: 0.5259, Val Precision: 0.5291, Val Recall: 0.5258, Val F1: 0.5257, Val ROC AUC: 0.716133605425895, Val RMSE: 0.9680\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [191/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9630, Test Acc: 0.5348, Test Precision: 0.5377, Test Recall: 0.5340, Test F1: 0.5331, Test ROC AUC: 0.7193366253902962, Test RMSE: 0.9525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:18<00:00, 30.72it/s]\n",
      "100%|██████████| 691/691 [00:21<00:00, 32.22it/s]\n",
      "100%|██████████| 346/346 [00:10<00:00, 33.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [196/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.8316, Train Acc: 0.6259, Train Precision: 0.6259, Train Recall: 0.6259, Train  F1: 0.6258,Train ROC AUC: 0.8093654474310417, Train RMSE: 0.8590\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [196/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9687, Val Acc: 0.5293, Val Precision: 0.5292, Val Recall: 0.5294, Val F1: 0.5288, Val ROC AUC: 0.7173359686040118, Val RMSE: 0.9718\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [196/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9571, Test Acc: 0.5268, Test Precision: 0.5262, Test Recall: 0.5268, Test F1: 0.5263, Test ROC AUC: 0.7223830192175485, Test RMSE: 0.9521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:27<00:00, 27.64it/s]\n",
      "100%|██████████| 691/691 [00:25<00:00, 26.96it/s]\n",
      "100%|██████████| 346/346 [00:12<00:00, 26.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [201/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.8178, Train Acc: 0.6369, Train Precision: 0.6370, Train Recall: 0.6369, Train  F1: 0.6368,Train ROC AUC: 0.8175029712740209, Train RMSE: 0.8489\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [201/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9630, Val Acc: 0.5398, Val Precision: 0.5415, Val Recall: 0.5404, Val F1: 0.5393, Val ROC AUC: 0.7234795927399915, Val RMSE: 0.9709\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [201/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9613, Test Acc: 0.5362, Test Precision: 0.5363, Test Recall: 0.5358, Test F1: 0.5342, Test ROC AUC: 0.7218108589064629, Test RMSE: 0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [02:03<00:00, 19.53it/s]\n",
      "100%|██████████| 691/691 [00:33<00:00, 20.48it/s]\n",
      "100%|██████████| 346/346 [00:17<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [206/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.8039, Train Acc: 0.6489, Train Precision: 0.6489, Train Recall: 0.6489, Train  F1: 0.6488,Train ROC AUC: 0.8253775380287509, Train RMSE: 0.8312\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [206/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9630, Val Acc: 0.5366, Val Precision: 0.5418, Val Recall: 0.5355, Val F1: 0.5349, Val ROC AUC: 0.7250500450395059, Val RMSE: 0.9221\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [206/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9559, Test Acc: 0.5413, Test Precision: 0.5481, Test Recall: 0.5416, Test F1: 0.5406, Test ROC AUC: 0.7293207332094873, Test RMSE: 0.9153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:45<00:00, 22.97it/s]\n",
      "100%|██████████| 691/691 [00:20<00:00, 33.23it/s]\n",
      "100%|██████████| 346/346 [00:12<00:00, 26.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [211/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7967, Train Acc: 0.6502, Train Precision: 0.6503, Train Recall: 0.6502, Train  F1: 0.6502,Train ROC AUC: 0.8282776321495273, Train RMSE: 0.8307\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [211/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9616, Val Acc: 0.5380, Val Precision: 0.5458, Val Recall: 0.5378, Val F1: 0.5337, Val ROC AUC: 0.72883431118033, Val RMSE: 0.9569\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [211/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9629, Test Acc: 0.5409, Test Precision: 0.5479, Test Recall: 0.5418, Test F1: 0.5383, Test ROC AUC: 0.7293988347284603, Test RMSE: 0.9343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:45<00:00, 22.99it/s]\n",
      "100%|██████████| 691/691 [00:26<00:00, 25.88it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 25.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [216/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7837, Train Acc: 0.6609, Train Precision: 0.6610, Train Recall: 0.6609, Train  F1: 0.6608,Train ROC AUC: 0.835709579200283, Train RMSE: 0.8168\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [216/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9487, Val Acc: 0.5444, Val Precision: 0.5447, Val Recall: 0.5443, Val F1: 0.5444, Val ROC AUC: 0.7328705856382022, Val RMSE: 0.9441\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [216/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9460, Test Acc: 0.5453, Test Precision: 0.5456, Test Recall: 0.5450, Test F1: 0.5451, Test ROC AUC: 0.7331710650311637, Test RMSE: 0.9389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:42<00:00, 23.58it/s]\n",
      "100%|██████████| 691/691 [00:25<00:00, 27.47it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 25.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [221/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7727, Train Acc: 0.6701, Train Precision: 0.6701, Train Recall: 0.6701, Train  F1: 0.6701,Train ROC AUC: 0.8410462362066831, Train RMSE: 0.8029\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [221/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9551, Val Acc: 0.5491, Val Precision: 0.5493, Val Recall: 0.5487, Val F1: 0.5486, Val ROC AUC: 0.7314662761966763, Val RMSE: 0.9320\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [221/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9452, Test Acc: 0.5489, Test Precision: 0.5497, Test Recall: 0.5490, Test F1: 0.5490, Test ROC AUC: 0.7358741190686167, Test RMSE: 0.9306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:38<00:00, 24.49it/s]\n",
      "100%|██████████| 691/691 [00:28<00:00, 24.54it/s]\n",
      "100%|██████████| 346/346 [00:15<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [226/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7595, Train Acc: 0.6716, Train Precision: 0.6716, Train Recall: 0.6715, Train  F1: 0.6715,Train ROC AUC: 0.8467565923884818, Train RMSE: 0.8005\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [226/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9479, Val Acc: 0.5447, Val Precision: 0.5473, Val Recall: 0.5449, Val F1: 0.5446, Val ROC AUC: 0.7363721946567763, Val RMSE: 0.9474\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [226/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9387, Test Acc: 0.5561, Test Precision: 0.5584, Test Recall: 0.5553, Test F1: 0.5548, Test ROC AUC: 0.740251093043868, Test RMSE: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:42<00:00, 23.64it/s]\n",
      "100%|██████████| 691/691 [00:27<00:00, 24.96it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 25.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [231/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7442, Train Acc: 0.6865, Train Precision: 0.6864, Train Recall: 0.6864, Train  F1: 0.6864,Train ROC AUC: 0.8549970273175832, Train RMSE: 0.7846\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [231/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9521, Val Acc: 0.5482, Val Precision: 0.5543, Val Recall: 0.5480, Val F1: 0.5446, Val ROC AUC: 0.7397547180857944, Val RMSE: 0.9372\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [231/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9447, Test Acc: 0.5510, Test Precision: 0.5564, Test Recall: 0.5518, Test F1: 0.5489, Test ROC AUC: 0.7430759744549968, Test RMSE: 0.9271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:35<00:00, 25.43it/s]\n",
      "100%|██████████| 691/691 [00:28<00:00, 24.43it/s]\n",
      "100%|██████████| 346/346 [00:14<00:00, 24.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [236/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7346, Train Acc: 0.6907, Train Precision: 0.6907, Train Recall: 0.6906, Train  F1: 0.6906,Train ROC AUC: 0.8589467651725332, Train RMSE: 0.7794\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [236/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9485, Val Acc: 0.5507, Val Precision: 0.5537, Val Recall: 0.5498, Val F1: 0.5488, Val ROC AUC: 0.739265582590504, Val RMSE: 0.9159\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [236/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9357, Test Acc: 0.5507, Test Precision: 0.5548, Test Recall: 0.5512, Test F1: 0.5507, Test ROC AUC: 0.7452698056638821, Test RMSE: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:19<00:00, 30.39it/s]\n",
      "100%|██████████| 691/691 [00:19<00:00, 34.84it/s]\n",
      "100%|██████████| 346/346 [00:10<00:00, 34.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [241/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7274, Train Acc: 0.6942, Train Precision: 0.6942, Train Recall: 0.6941, Train  F1: 0.6941,Train ROC AUC: 0.861764600620746, Train RMSE: 0.7732\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [241/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9344, Val Acc: 0.5538, Val Precision: 0.5558, Val Recall: 0.5546, Val F1: 0.5532, Val ROC AUC: 0.7456717543738393, Val RMSE: 0.9472\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [241/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9376, Test Acc: 0.5507, Test Precision: 0.5520, Test Recall: 0.5499, Test F1: 0.5486, Test ROC AUC: 0.743648440152718, Test RMSE: 0.9476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:24<00:00, 28.44it/s]\n",
      "100%|██████████| 691/691 [00:25<00:00, 27.23it/s]\n",
      "100%|██████████| 346/346 [00:10<00:00, 33.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [246/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7121, Train Acc: 0.7012, Train Precision: 0.7013, Train Recall: 0.7012, Train  F1: 0.7012,Train ROC AUC: 0.8684664099073242, Train RMSE: 0.7642\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [246/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9360, Val Acc: 0.5578, Val Precision: 0.5610, Val Recall: 0.5572, Val F1: 0.5570, Val ROC AUC: 0.7478248799030478, Val RMSE: 0.9182\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [246/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9304, Test Acc: 0.5507, Test Precision: 0.5546, Test Recall: 0.5504, Test F1: 0.5504, Test ROC AUC: 0.7488030698650382, Test RMSE: 0.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:20<00:00, 29.92it/s]\n",
      "100%|██████████| 691/691 [00:30<00:00, 22.44it/s]\n",
      "100%|██████████| 346/346 [00:15<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [251/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.7045, Train Acc: 0.7028, Train Precision: 0.7027, Train Recall: 0.7027, Train  F1: 0.7027,Train ROC AUC: 0.871231751262131, Train RMSE: 0.7648\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [251/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9366, Val Acc: 0.5628, Val Precision: 0.5644, Val Recall: 0.5631, Val F1: 0.5629, Val ROC AUC: 0.7483460108272109, Val RMSE: 0.9246\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [251/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9285, Test Acc: 0.5583, Test Precision: 0.5592, Test Recall: 0.5577, Test F1: 0.5575, Test ROC AUC: 0.7497116667523521, Test RMSE: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:46<00:00, 22.71it/s]\n",
      "100%|██████████| 691/691 [00:28<00:00, 23.97it/s]\n",
      "100%|██████████| 346/346 [00:14<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [256/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6936, Train Acc: 0.7114, Train Precision: 0.7114, Train Recall: 0.7114, Train  F1: 0.7113,Train ROC AUC: 0.8755254815329301, Train RMSE: 0.7487\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [256/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9316, Val Acc: 0.5623, Val Precision: 0.5625, Val Recall: 0.5626, Val F1: 0.5623, Val ROC AUC: 0.7503922012039418, Val RMSE: 0.9302\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [256/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9156, Test Acc: 0.5717, Test Precision: 0.5718, Test Recall: 0.5713, Test F1: 0.5711, Test ROC AUC: 0.7559702239641722, Test RMSE: 0.9224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:32<00:00, 26.00it/s]\n",
      "100%|██████████| 691/691 [00:28<00:00, 23.86it/s]\n",
      "100%|██████████| 346/346 [00:15<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [261/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6845, Train Acc: 0.7160, Train Precision: 0.7159, Train Recall: 0.7159, Train  F1: 0.7158,Train ROC AUC: 0.8796431956680739, Train RMSE: 0.7410\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [261/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9326, Val Acc: 0.5672, Val Precision: 0.5725, Val Recall: 0.5660, Val F1: 0.5650, Val ROC AUC: 0.7539803830372201, Val RMSE: 0.8902\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [261/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9305, Test Acc: 0.5641, Test Precision: 0.5707, Test Recall: 0.5647, Test F1: 0.5640, Test ROC AUC: 0.753979970301938, Test RMSE: 0.8851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:36<00:00, 25.09it/s]\n",
      "100%|██████████| 691/691 [00:26<00:00, 26.20it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [266/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6720, Train Acc: 0.7254, Train Precision: 0.7254, Train Recall: 0.7254, Train  F1: 0.7253,Train ROC AUC: 0.8841381518349966, Train RMSE: 0.7283\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [266/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9280, Val Acc: 0.5674, Val Precision: 0.5677, Val Recall: 0.5674, Val F1: 0.5674, Val ROC AUC: 0.7546864029946753, Val RMSE: 0.9151\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [266/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9193, Test Acc: 0.5746, Test Precision: 0.5747, Test Recall: 0.5742, Test F1: 0.5741, Test ROC AUC: 0.7577603110231325, Test RMSE: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:33<00:00, 25.74it/s]\n",
      "100%|██████████| 691/691 [00:22<00:00, 30.43it/s]\n",
      "100%|██████████| 346/346 [00:11<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [271/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6623, Train Acc: 0.7276, Train Precision: 0.7276, Train Recall: 0.7276, Train  F1: 0.7275,Train ROC AUC: 0.8880939273681617, Train RMSE: 0.7269\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [271/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9209, Val Acc: 0.5728, Val Precision: 0.5755, Val Recall: 0.5721, Val F1: 0.5717, Val ROC AUC: 0.758987590363346, Val RMSE: 0.8928\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [271/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9174, Test Acc: 0.5717, Test Precision: 0.5741, Test Recall: 0.5721, Test F1: 0.5718, Test ROC AUC: 0.7588072091065973, Test RMSE: 0.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:21<00:00, 29.75it/s]\n",
      "100%|██████████| 691/691 [00:22<00:00, 30.54it/s]\n",
      "100%|██████████| 346/346 [00:12<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [276/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6497, Train Acc: 0.7346, Train Precision: 0.7346, Train Recall: 0.7345, Train  F1: 0.7345,Train ROC AUC: 0.8928589748728983, Train RMSE: 0.7158\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [276/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9220, Val Acc: 0.5791, Val Precision: 0.5803, Val Recall: 0.5797, Val F1: 0.5790, Val ROC AUC: 0.7606408294358239, Val RMSE: 0.9131\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [276/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9169, Test Acc: 0.5728, Test Precision: 0.5734, Test Recall: 0.5721, Test F1: 0.5715, Test ROC AUC: 0.7603598342519037, Test RMSE: 0.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:20<00:00, 30.10it/s]\n",
      "100%|██████████| 691/691 [00:22<00:00, 30.29it/s]\n",
      "100%|██████████| 346/346 [00:11<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [281/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6436, Train Acc: 0.7371, Train Precision: 0.7371, Train Recall: 0.7371, Train  F1: 0.7370,Train ROC AUC: 0.8946091604751941, Train RMSE: 0.7123\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [281/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9234, Val Acc: 0.5800, Val Precision: 0.5815, Val Recall: 0.5805, Val F1: 0.5799, Val ROC AUC: 0.7597569461585723, Val RMSE: 0.9081\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [281/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9124, Test Acc: 0.5789, Test Precision: 0.5803, Test Recall: 0.5782, Test F1: 0.5778, Test ROC AUC: 0.7633010969597027, Test RMSE: 0.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:20<00:00, 29.97it/s]\n",
      "100%|██████████| 691/691 [00:22<00:00, 30.21it/s]\n",
      "100%|██████████| 346/346 [00:11<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [286/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6286, Train Acc: 0.7448, Train Precision: 0.7448, Train Recall: 0.7448, Train  F1: 0.7447,Train ROC AUC: 0.9003672619137976, Train RMSE: 0.6999\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [286/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9347, Val Acc: 0.5746, Val Precision: 0.5789, Val Recall: 0.5741, Val F1: 0.5732, Val ROC AUC: 0.761633788757132, Val RMSE: 0.8949\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [286/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9208, Test Acc: 0.5757, Test Precision: 0.5794, Test Recall: 0.5762, Test F1: 0.5756, Test ROC AUC: 0.762369342763555, Test RMSE: 0.8860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:20<00:00, 30.13it/s]\n",
      "100%|██████████| 691/691 [00:22<00:00, 30.78it/s]\n",
      "100%|██████████| 346/346 [00:11<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [291/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6244, Train Acc: 0.7468, Train Precision: 0.7468, Train Recall: 0.7468, Train  F1: 0.7468,Train ROC AUC: 0.9017596795402342, Train RMSE: 0.7054\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [291/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9199, Val Acc: 0.5766, Val Precision: 0.5783, Val Recall: 0.5767, Val F1: 0.5766, Val ROC AUC: 0.7646050769254359, Val RMSE: 0.8995\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [291/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9103, Test Acc: 0.5742, Test Precision: 0.5763, Test Recall: 0.5737, Test F1: 0.5737, Test ROC AUC: 0.7662462815306975, Test RMSE: 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:18<00:00, 30.79it/s]\n",
      "100%|██████████| 691/691 [00:22<00:00, 30.74it/s]\n",
      "100%|██████████| 346/346 [00:11<00:00, 31.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [296/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6130, Train Acc: 0.7523, Train Precision: 0.7522, Train Recall: 0.7522, Train  F1: 0.7522,Train ROC AUC: 0.9056961223185448, Train RMSE: 0.6923\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [296/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9311, Val Acc: 0.5773, Val Precision: 0.5815, Val Recall: 0.5765, Val F1: 0.5757, Val ROC AUC: 0.7632358197361621, Val RMSE: 0.8876\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [296/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9243, Test Acc: 0.5746, Test Precision: 0.5791, Test Recall: 0.5751, Test F1: 0.5748, Test ROC AUC: 0.762403081940301, Test RMSE: 0.8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:19<00:00, 30.33it/s]\n",
      "100%|██████████| 691/691 [00:20<00:00, 34.06it/s]\n",
      "100%|██████████| 346/346 [00:09<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [301/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.6015, Train Acc: 0.7581, Train Precision: 0.7580, Train Recall: 0.7580, Train  F1: 0.7580,Train ROC AUC: 0.9094877629403638, Train RMSE: 0.6851\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [301/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9315, Val Acc: 0.5791, Val Precision: 0.5848, Val Recall: 0.5801, Val F1: 0.5780, Val ROC AUC: 0.7656169032037053, Val RMSE: 0.9214\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [301/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9258, Test Acc: 0.5840, Test Precision: 0.5883, Test Recall: 0.5828, Test F1: 0.5808, Test ROC AUC: 0.765604832405885, Test RMSE: 0.9145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:32<00:00, 26.15it/s]\n",
      "100%|██████████| 691/691 [00:27<00:00, 25.32it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 25.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [306/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.5961, Train Acc: 0.7641, Train Precision: 0.7641, Train Recall: 0.7641, Train  F1: 0.7640,Train ROC AUC: 0.9113512634189732, Train RMSE: 0.6767\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [306/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9211, Val Acc: 0.5793, Val Precision: 0.5843, Val Recall: 0.5803, Val F1: 0.5781, Val ROC AUC: 0.7687868662836413, Val RMSE: 0.9172\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [306/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9176, Test Acc: 0.5844, Test Precision: 0.5898, Test Recall: 0.5831, Test F1: 0.5815, Test ROC AUC: 0.7671333489343902, Test RMSE: 0.9143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:37<00:00, 24.82it/s]\n",
      "100%|██████████| 691/691 [00:26<00:00, 26.24it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 26.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [311/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.5880, Train Acc: 0.7670, Train Precision: 0.7669, Train Recall: 0.7669, Train  F1: 0.7669,Train ROC AUC: 0.9140669538042071, Train RMSE: 0.6713\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [311/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9246, Val Acc: 0.5880, Val Precision: 0.5956, Val Recall: 0.5869, Val F1: 0.5867, Val ROC AUC: 0.770572015841373, Val RMSE: 0.8581\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [311/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9169, Test Acc: 0.5829, Test Precision: 0.5917, Test Recall: 0.5831, Test F1: 0.5829, Test ROC AUC: 0.7702363756429772, Test RMSE: 0.8563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:39<00:00, 24.27it/s]\n",
      "100%|██████████| 691/691 [00:27<00:00, 25.00it/s]\n",
      "100%|██████████| 346/346 [00:14<00:00, 24.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [316/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.5769, Train Acc: 0.7713, Train Precision: 0.7714, Train Recall: 0.7713, Train  F1: 0.7712,Train ROC AUC: 0.9173634577269016, Train RMSE: 0.6704\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [316/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9249, Val Acc: 0.5911, Val Precision: 0.5974, Val Recall: 0.5902, Val F1: 0.5894, Val ROC AUC: 0.771104045555286, Val RMSE: 0.8664\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [316/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9162, Test Acc: 0.5818, Test Precision: 0.5892, Test Recall: 0.5826, Test F1: 0.5818, Test ROC AUC: 0.7720653669985413, Test RMSE: 0.8651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:40<00:00, 24.11it/s]\n",
      "100%|██████████| 691/691 [00:27<00:00, 24.79it/s]\n",
      "100%|██████████| 346/346 [00:14<00:00, 24.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [321/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.5683, Train Acc: 0.7777, Train Precision: 0.7777, Train Recall: 0.7777, Train  F1: 0.7776,Train ROC AUC: 0.9202034328939233, Train RMSE: 0.6569\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [321/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9161, Val Acc: 0.5925, Val Precision: 0.5951, Val Recall: 0.5922, Val F1: 0.5919, Val ROC AUC: 0.7739152899072709, Val RMSE: 0.8752\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [321/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9023, Test Acc: 0.5941, Test Precision: 0.5962, Test Recall: 0.5946, Test F1: 0.5941, Test ROC AUC: 0.7769926685688825, Test RMSE: 0.8674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:40<00:00, 24.12it/s]\n",
      "100%|██████████| 691/691 [00:28<00:00, 24.64it/s]\n",
      "100%|██████████| 346/346 [00:13<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [326/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.5620, Train Acc: 0.7749, Train Precision: 0.7749, Train Recall: 0.7749, Train  F1: 0.7749,Train ROC AUC: 0.9218260453928383, Train RMSE: 0.6612\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [326/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9062, Val Acc: 0.5982, Val Precision: 0.5993, Val Recall: 0.5986, Val F1: 0.5980, Val ROC AUC: 0.7765271853687098, Val RMSE: 0.8875\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [326/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.8992, Test Acc: 0.5985, Test Precision: 0.5993, Test Recall: 0.5979, Test F1: 0.5976, Test ROC AUC: 0.7781618397002082, Test RMSE: 0.8823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:15<00:00, 32.09it/s]\n",
      "100%|██████████| 691/691 [00:20<00:00, 33.89it/s]\n",
      "100%|██████████| 346/346 [00:10<00:00, 34.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [331/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.5536, Train Acc: 0.7805, Train Precision: 0.7804, Train Recall: 0.7804, Train  F1: 0.7804,Train ROC AUC: 0.9244970724501426, Train RMSE: 0.6470\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [331/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9152, Val Acc: 0.5962, Val Precision: 0.5963, Val Recall: 0.5965, Val F1: 0.5961, Val ROC AUC: 0.7742456177962792, Val RMSE: 0.8824\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [331/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9024, Test Acc: 0.5981, Test Precision: 0.5977, Test Recall: 0.5980, Test F1: 0.5978, Test ROC AUC: 0.7778806078828104, Test RMSE: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2416/2416 [01:13<00:00, 32.90it/s]\n",
      "100%|██████████| 691/691 [00:20<00:00, 33.57it/s]\n",
      "100%|██████████| 346/346 [00:10<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Values After Training-----------\n",
      "\n",
      "Epoch: [336/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001 \n",
      "Optimizer: AdamW \n",
      "Train Loss: 0.5428, Train Acc: 0.7887, Train Precision: 0.7887, Train Recall: 0.7887, Train  F1: 0.7886,Train ROC AUC: 0.9277631353778872, Train RMSE: 0.6363\n",
      "\n",
      "\n",
      "-----------Values After Validation-----------\n",
      "\n",
      "Epoch: [336/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW \n",
      "Val Loss: 0.9169, Val Acc: 0.5938, Val Precision: 0.5954, Val Recall: 0.5944, Val F1: 0.5932, Val ROC AUC: 0.7768070710633, Val RMSE: 0.8945\n",
      "\n",
      "\n",
      "-----------Values After Testing-----------\n",
      "\n",
      "Epoch: [336/501] \n",
      "Batch Size: 8 \n",
      "Learning Rate: 0.0001\n",
      "Optimizer: AdamW Test Loss: 0.9109, Test Acc: 0.5956, Test Precision: 0.5957, Test Recall: 0.5954, Test F1: 0.5943, Test ROC AUC: 0.7755742125111768, Test RMSE: 0.8815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1761/2416 [00:56<00:19, 33.90it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  \n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from pytorch_lamb import Lamb\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "batch_sizes = [8]\n",
    "learning_rates = [0.0001]\n",
    "optimizers_list = ['AdamW']\n",
    "num_classes=3\n",
    "total_epochs =501\n",
    "start=100\n",
    "step=5\n",
    "\n",
    "\n",
    "\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \"../Preprocessing/skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='weighted', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            model = CLIPSkinClassifier(clip_model, num_classes=num_classes).to(device).float()\n",
    "            \n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = get_optimizer(optimizer_name,model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                \n",
    "                \n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc if train_roc_auc is not None else 'N/A'}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc if train_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                \n",
    "                \n",
    "                overall_result = {\n",
    "                    'Epoch': epoch ,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'special final testing.csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
