{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from vit_pytorch import ViT\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lamb import Lamb\n",
    "from torch.optim import AdamW\n",
    "import timm \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#unprocessed Data\n",
    "# dataset_path = '../skinType' \n",
    "\n",
    "#preprocessed Data\n",
    "dataset_path = '../Preprocessing/Processed_Images'\n",
    "#dataset_path=\"../skintypepatches 128x128\"\n",
    "#_FaceCrops_256' \n",
    "\n",
    "# Define hyperparameters\n",
    "batch_sizes = [ 8, 32,64]\n",
    "learning_rates =[0.01, 0.001]\n",
    "optimizers_list = ['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "\n",
    "num_classes = 3  # Dry, Normal, Oily skin types\n",
    "#class_names = ['oily', 'dry', 'normal']\n",
    "steps_per_epoch = 20 \n",
    "total_epochs=500\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "# Load Dataset\n",
    "transform = transforms.Compose([\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(10),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std)\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean, std)\n",
    "# ])\n",
    "# Dataset Path\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.20 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "#val_dataset.dataset.transform = val_transform\n",
    "print(f\"train size {train_size}\")\n",
    "print(f\"Val size {val_size}\")\n",
    "print(f\"Test Size {test_size}\")\n",
    "\n",
    "# print(f\"train Dataset {train_dataset}\")\n",
    "# print(f\"Val Dataset {val_dataset}\")\n",
    "# print(f\"Test Dataset {test_dataset}\")\n",
    "\n",
    "# Function to initialize the model\n",
    "# def create_vit_model():    \n",
    "#     model = ViT(\n",
    "#         image_size=128,\n",
    "#         patch_size=16,\n",
    "#         num_classes=num_classes,  \n",
    "#         dim=512,                      \n",
    "#         heads=8,  \n",
    "#         depth=8,              \n",
    "#         mlp_dim=512,          \n",
    "#         dropout=0.4,           \n",
    "#         emb_dropout=0.4        \n",
    "#     )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# Optimizer choices\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return optim.AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    y_true, y_pred = [], []\n",
    "    all_probs = []\n",
    "\n",
    "    for inputs, labels in tqdm(loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.detach().cpu().numpy())\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    try:\n",
    "        unique_classes = np.unique(all_labels)\n",
    "        if len(unique_classes) == num_classes:\n",
    "            roc_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr', average='weighted')\n",
    "        else:\n",
    "            roc_auc = None\n",
    "    except ValueError:\n",
    "        roc_auc = None \n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "\n",
    "    return running_loss / len(loader), accuracy, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Validation and Test Function\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    all_probs = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        unique_classes = np.unique(all_labels)\n",
    "        if len(unique_classes) == num_classes:\n",
    "            roc_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr', average='weighted')\n",
    "        else:\n",
    "            print(\"Warning: Not all classes are present in the evaluation set. Skipping ROC-AUC calculation.\")\n",
    "            roc_auc = None\n",
    "    except ValueError:\n",
    "        roc_auc = None  \n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "    \n",
    "    return running_loss / len(loader), accuracy, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "# Main training loop\n",
    "def train_and_evaluate(batch_size, lr, optimizer_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "    model.to(device)\n",
    "    optimizer = get_optimizer(optimizer_name, model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    # Training\n",
    "    for epoch in range(100,total_epochs,20):\n",
    "        # print(\"\\n\\n-------------------------Checking Weights in Each Iteration----------------------------\")\n",
    "        # print(\"Initial Weights:\")\n",
    "        # print_weights(model)\n",
    "        # print(\"\\n\\n-------------------------Checking Weights in Each Iteration-----------------------------\")\n",
    "  \n",
    "        train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse= evaluate_model(model, val_loader, criterion, device)\n",
    "        test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step()\n",
    "        scheduler.step(val_loss)\n",
    "        print(\"----------Values After Training-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "              f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                   f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                   f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "              f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                    f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                    f\"Val RMSE: {val_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "              f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                    f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "                \n",
    "        \n",
    "       \n",
    "        \n",
    "        #Saving Training data\n",
    "        overall_result = {\n",
    "            'Epoch': epoch + 1,\n",
    "            'Batch Size': batch_size,\n",
    "            'Learning Rate': lr,\n",
    "            'Optimizer': optimizer_name,\n",
    "            \n",
    "            'Train Loss':round(train_loss, 4),\n",
    "            'Test Loss':round(test_loss, 4),\n",
    "            'Val Loss':round(val_loss, 4),\n",
    "            \n",
    "            'Train Acc': round(train_acc, 4),\n",
    "            'Test Acc': round(test_acc, 4),\n",
    "            'Val Acc': round(val_acc, 4),\n",
    "            \n",
    "            \n",
    "            'Train Precision': round(train_precision, 4),\n",
    "            'Test Precision': round(test_precision, 4),\n",
    "            'Val Precision': round(val_precision, 4),\n",
    "            \n",
    "            'Train Recall': round(train_recall, 4),\n",
    "            'Test Recall': round(test_recall, 4),\n",
    "            'Val Recall': round(val_recall, 4),\n",
    "            \n",
    "            'Train F1 Score': round(train_f1, 4),\n",
    "            'Test F1 Score': round(test_f1, 4),\n",
    "            'Val F1 Score': round(val_f1, 4),\n",
    "            \n",
    "            'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "            'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "            'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "            \n",
    "            'Train RMSE': round(train_rmse, 4),\n",
    "            'Test RMSE': round(test_rmse, 4),\n",
    "            'Val RMSE': round(val_rmse, 4)\n",
    "        }\n",
    "        \n",
    "        # Append to CSV\n",
    "        overall_result_file = 'pretrained_overall_result.csv'\n",
    "        \n",
    "        if not os.path.isfile(overall_result_file):\n",
    "            pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)        \n",
    "        else:\n",
    "            pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "            \n",
    "    # Save the trained model\n",
    "    os.makedirs('../saved_models', exist_ok=True)\n",
    "    model_save_path = f\"../saved_models/vit_model_bs{batch_size}_lr{lr}_optimizer{optimizer_name}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # # Convert results into DataFrame\n",
    "    df_results = pd.read_csv('pretrained_overall_result.csv')\n",
    "\n",
    "    # Reshape the dataframe to long format for seaborn\n",
    "    df_long = pd.melt(df_results, id_vars=['Epoch'], var_name='Metric', value_name='Value')\n",
    "\n",
    "    # Optional: Drop rows with NaN values in the Value column (if any)\n",
    "    df_long = df_long.dropna(subset=['Value'])\n",
    "\n",
    "    # Set up the plots with a style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Plot Loss (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Loss', 'Test Loss', 'Val Loss'])],x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Accuracy (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Acc', 'Test Acc', 'Val Acc'])],\n",
    "                x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Precision (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Precision', 'Test Precision', 'Val Precision'])],x='Epoch', y='Value', \n",
    "                 hue='Metric')\n",
    "    plt.title('Precision Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Recall (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train Recall', 'Test Recall', 'Val Recall'])],x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('Recall Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot F1 Score (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train F1 Score', 'Test F1 Score', 'Val F1 Score'])],\n",
    "                x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('F1 Score Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC AUC (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train ROC AUC', 'Test ROC AUC', 'Val ROC AUC'])],\n",
    "                x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('ROC AUC Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ROC AUC')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot RMSE (Train, Test, Val)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_long[df_long['Metric'].isin(['Train RMSE', 'Test RMSE', 'Val RMSE'])],\n",
    "                x='Epoch', y='Value', hue='Metric')\n",
    "    plt.title('RMSE Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()\n",
    "\n",
    "    # return test_acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "                #test_metrics = \n",
    "                train_and_evaluate(batch_size, lr, optimizer_name)\n",
    "                # print(f\"Final Test Metrics with Batch Size {batch_size}, LR {lr}, Optimizer {optimizer_name}: {test_metrics}\")\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Model With Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb\n",
    "import clip\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [8]\n",
    "learning_rates = [0.01, 0.001]\n",
    "optimizers_list = ['LAMB', 'AdamW']\n",
    "\n",
    "# batch_sizes = [8, 32, 64]\n",
    "# learning_rates = [0.01, 0.001]\n",
    "# optimizers_list = ['LAMB', 'AdamW']\n",
    "\n",
    "total_epochs = 250\n",
    "start=1\n",
    "step=1\n",
    "\n",
    "# Load CLIP model and preprocessing\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "data_dir = r\"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "# Data Splitting\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "print(f\"train size {train_size}\")\n",
    "print(f\"Val size {val_size}\")\n",
    "print(f\"Test Size {test_size}\")\n",
    "\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return optim.AdamW(model_params, lr=lr,weight_decay=weight_decay)\n",
    "    elif optimizer_name=='LAMB':\n",
    "        return Lamb(model_params, lr=lr,weight_decay=weight_decay)\n",
    "    \n",
    "    \n",
    "# Freeze CLIP vision encoder\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Model definition\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "model = CLIPSkinClassifier(clip_model, num_classes=3).to(device).float()\n",
    "\n",
    "\n",
    "\n",
    "# Metric helper\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Train loop\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Eval loop\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Training loop with logging\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            # Loss and optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = Lamb(model.parameters(), lr=lr)\n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                # Save results to CSV\n",
    "                overall_result = {\n",
    "                    'Epoch': epoch + 1,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'sample result (250).csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "\n",
    "            # Save model\n",
    "            os.makedirs('../saved_models', exist_ok=True)\n",
    "            model_save_path = f\"../saved_models/vit_model_bs{batch_size}_lr{lr}_optimizer{optimizer_name}.pth\"\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb\n",
    "import clip\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [8]\n",
    "learning_rates = [0.001]\n",
    "optimizers_list = ['LAMB', 'AdamW']\n",
    "total_epochs = 500\n",
    "start=100\n",
    "step=20\n",
    "\n",
    "# Load CLIP model and preprocessing\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "data_dir = r\"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "# Data Splitting\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"train size {train_size}\")\n",
    "print(f\"Val size {val_size}\")\n",
    "print(f\"Test Size {test_size}\")\n",
    "\n",
    "\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return optim.AdamW(model_params, lr=lr,weight_decay=weight_decay)\n",
    "    elif optimizer_name=='LAMB':\n",
    "        return Lamb(model_params, lr=lr,weight_decay=weight_decay)\n",
    "    \n",
    "    \n",
    "# Freeze CLIP vision encoder\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Model definition\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "model = CLIPSkinClassifier(clip_model, num_classes=3).to(device).float()\n",
    "\n",
    "\n",
    "\n",
    "# Metric helper\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Train loop\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Eval loop\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Training loop with logging\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            # Loss and optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = Lamb(model.parameters(), lr=lr)\n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                # Save results to CSV\n",
    "                overall_result = {\n",
    "                    'Epoch': epoch + 1,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'sample result (250).csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "\n",
    "            # Save model\n",
    "            os.makedirs('../saved_models', exist_ok=True)\n",
    "            model_save_path = f\"../saved_models/vit_model_bs{batch_size}_lr{lr}_optimizer{optimizer_name}.pth\"\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  # You may need to install this via pip install pytorch-optimizer\n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "lr = 0.0001\n",
    "optimizer_name = \"AdamW\"\n",
    "total_epochs = 501\n",
    "start=1\n",
    "step=1\n",
    "\n",
    "# Load CLIP model and preprocessing\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "data_dir = \"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "# Data Splitting\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Freeze CLIP vision encoder\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Model definition\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "model = CLIPSkinClassifier(clip_model, num_classes=3).to(device).float()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Lamb(model.parameters(), lr=lr)\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "# Metric helper\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Train loop\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Eval loop\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Training loop with logging\n",
    "for epoch in range(start,total_epochs,step):\n",
    "    train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "    test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "    print(\"----------Values After Training-----------\")\n",
    "    print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "          f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "               f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "               f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "    print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "    print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "          f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "    print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "    print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "          f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    overall_result = {\n",
    "        'Epoch': epoch + 1,\n",
    "        'Batch Size': batch_size,\n",
    "        'Learning Rate': lr,\n",
    "        'Optimizer': optimizer_name,\n",
    "\n",
    "        'Train Loss': round(train_loss, 4),\n",
    "        'Test Loss': round(test_loss, 4),\n",
    "        'Val Loss': round(val_loss, 4),\n",
    "\n",
    "        'Train Acc': round(train_acc, 4),\n",
    "        'Test Acc': round(test_acc, 4),\n",
    "        'Val Acc': round(val_acc, 4),\n",
    "\n",
    "        'Train Precision': round(train_precision, 4),\n",
    "        'Test Precision': round(test_precision, 4),\n",
    "        'Val Precision': round(val_precision, 4),\n",
    "\n",
    "        'Train Recall': round(train_recall, 4),\n",
    "        'Test Recall': round(test_recall, 4),\n",
    "        'Val Recall': round(val_recall, 4),\n",
    "\n",
    "        'Train F1 Score': round(train_f1, 4),\n",
    "        'Test F1 Score': round(test_f1, 4),\n",
    "        'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "        'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "        'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "        'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "        'Train RMSE': round(train_rmse, 4),\n",
    "        'Test RMSE': round(test_rmse, 4),\n",
    "        'Val RMSE': round(val_rmse, 4)\n",
    "    }\n",
    "\n",
    "    overall_result_file = 'test with shuffle.csv'\n",
    "    if not os.path.isfile(overall_result_file):\n",
    "        pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "    else:\n",
    "        pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  \n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from pytorch_lamb import Lamb\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "batch_sizes = [8,16,32,64]\n",
    "learning_rates = [0.1,0.01,0.001,0.0001,0.00001]\n",
    "optimizers_list = ['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "num_classes=3\n",
    "total_epochs = 2\n",
    "start=1\n",
    "step=1\n",
    "\n",
    "\n",
    "\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \"../skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            model = CLIPSkinClassifier(clip_model, num_classes=num_classes).to(device).float()\n",
    "            \n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = get_optimizer(optimizer_name,model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                \n",
    "                \n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc if train_roc_auc is not None else 'N/A'}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc if train_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                \n",
    "                \n",
    "                overall_result = {\n",
    "                    'Epoch': epoch + 1,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'final testing.csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  \n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from pytorch_lamb import Lamb\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "batch_sizes = [8]\n",
    "learning_rates = [0.001]\n",
    "optimizers_list = ['AdamW','RAdam']\n",
    "num_classes=3\n",
    "total_epochs =501\n",
    "start=100\n",
    "step=5\n",
    "\n",
    "\n",
    "\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \"../Preprocessing/skintypepatches 128x128\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='weighted', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            model = CLIPSkinClassifier(clip_model, num_classes=num_classes).to(device).float()\n",
    "            \n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = get_optimizer(optimizer_name,model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                \n",
    "                \n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc if train_roc_auc is not None else 'N/A'}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc if train_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                \n",
    "                \n",
    "                overall_result = {\n",
    "                    'Epoch': epoch ,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'special final testing.csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  \n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from pytorch_lamb import Lamb\n",
    "from torch_optimizer import RAdam\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "batch_sizes = [4,8,16,32,64]\n",
    "#[4,8,16,32,64]\n",
    "learning_rates = [0.1,0.01,0.001,0.0001,0.00001]\n",
    "#[0.1,0.01,0.001,0.0001,0.00001]\n",
    "optimizers_list = ['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "#['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "num_classes=3\n",
    "total_epochs = 501\n",
    "start=100\n",
    "step=5\n",
    "\n",
    "\n",
    "\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "#without augmentataion\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "#with augmentaion\n",
    "# aug_transform = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(p=0.8),\n",
    "#     transforms.RandomVerticalFlip(p=0.8),\n",
    "#     transforms.RandomRotation(45),     \n",
    "#     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "#     #transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.25)),  \n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "#                          (0.26862954, 0.26130258, 0.27577711))\n",
    "# ])\n",
    "\n",
    "data_dir = \"../Preprocessing/stage3patches\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#you have frozen the entire CLIP visual encoder:\n",
    "# for param in clip_model.visual.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "#unfreze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "#unfreeze last 4 layers:\n",
    "# for name, param in clip_model.visual.named_parameters():\n",
    "#     if \"transformer.resblocks.8\" in name or \\\n",
    "#        \"transformer.resblocks.9\" in name or \\\n",
    "#        \"transformer.resblocks.10\" in name or \\\n",
    "#        \"transformer.resblocks.11\" in name:\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "\n",
    "# class CLIPSkinClassifier(nn.Module):\n",
    "#     def __init__(self, clip_model, num_classes=3):\n",
    "#         super(CLIPSkinClassifier, self).__init__()\n",
    "#         self.encoder = clip_model.visual\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(self.encoder.output_dim, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(128, num_classes)\n",
    "#         )\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.encoder(x)\n",
    "#         logits = self.classifier(features)\n",
    "#         return logits\n",
    "\n",
    "\n",
    "\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.clip_model = clip_model\n",
    "        self.fc1 = nn.Linear(clip_model.visual.output_dim, 512)  # Increased size\n",
    "        self.fc2 = nn.Linear(512, 256)  # Adjusted for more capacity\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.clip_model.encode_image(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.01):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "# kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            model = CLIPSkinClassifier(clip_model, num_classes=num_classes).to(device).float()\n",
    "            \n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "            optimizer = get_optimizer(optimizer_name,model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                \n",
    "                \n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name}, \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name}, \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc if train_roc_auc is not None else 'N/A'}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc if train_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                \n",
    "                \n",
    "                overall_result = {\n",
    "                    'Epoch': epoch ,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = f'../Sample testing/Test 14/Batch {batch_size} model parameter testing.csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "                \n",
    "                \n",
    "                # model_save_path = f\"../saved_models/Batch{batch_size}_LR{lr}_Optim{optimizer_name}.pth\"\n",
    "                # torch.save(model.state_dict(), model_save_path)\n",
    "                # print(f\"Model saved to {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip based Vit with K folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  \n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from pytorch_lamb import Lamb\n",
    "from torch_optimizer import RAdam\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "batch_sizes = [16]\n",
    "#[4,8,16,32,64]\n",
    "learning_rates = [0.001]\n",
    "#[0.1,0.01,0.001,0.0001,0.00001]\n",
    "optimizers_list = ['LAMB', 'RAdam']\n",
    "#['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "num_classes=2\n",
    "total_epochs = 501\n",
    "start=100\n",
    "step=5\n",
    "\n",
    "\n",
    "\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "#without augmentataion\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "#with augmentaion\n",
    "# aug_transform = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(p=0.8),\n",
    "#     transforms.RandomVerticalFlip(p=0.8),\n",
    "#     transforms.RandomRotation(45),     \n",
    "#     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "#     #transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.25)),  \n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "#                          (0.26862954, 0.26130258, 0.27577711))\n",
    "# ])\n",
    "\n",
    "data_dir = r\"../Preprocessing/New Dataset\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "class RGBAImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = Image.open(path)\n",
    "        \n",
    "        # Convert palette images to RGBA to avoid warning\n",
    "        if sample.mode == 'P':\n",
    "            sample = Image.open(path).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "# dataset = RGBAImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#you have frozen the entire CLIP visual encoder:\n",
    "# for param in clip_model.visual.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "#unfreeze last 4 layers:\n",
    "# for name, param in clip_model.visual.named_parameters():\n",
    "#     if \"transformer.resblocks.8\" in name or \\\n",
    "#        \"transformer.resblocks.9\" in name or \\\n",
    "#        \"transformer.resblocks.10\" in name or \\\n",
    "#        \"transformer.resblocks.11\" in name:\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "\n",
    "# class CLIPSkinClassifier(nn.Module):\n",
    "#     def __init__(self, clip_model, num_classes=3):\n",
    "#         super(CLIPSkinClassifier, self).__init__()\n",
    "#         self.encoder = clip_model.visual\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(self.encoder.output_dim, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(128, num_classes)\n",
    "#         )\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.encoder(x)\n",
    "#         logits = self.classifier(features)\n",
    "#         return logits\n",
    "\n",
    "\n",
    "\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.clip_model = clip_model\n",
    "        self.fc1 = nn.Linear(clip_model.visual.output_dim, 512)  # Increased size\n",
    "        self.fc2 = nn.Linear(512, 256)  # Adjusted for more capacity\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.clip_model.encode_image(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.01):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "# Define the number of folds\n",
    "k_folds = 10\n",
    "\n",
    "# Set up KFold\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True,random_state=42)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "                print(f'Fold {fold + 1}/{k_folds}')\n",
    "                \n",
    "                # Create subsets for training and validation\n",
    "                train_subset = Subset(dataset, train_idx)\n",
    "                val_subset = Subset(dataset, val_idx)\n",
    "                \n",
    "                # Create data loaders for training and validation\n",
    "                train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "                \n",
    "            \n",
    "                model = CLIPSkinClassifier(clip_model, num_classes=num_classes).to(device).float()\n",
    "                #unfreze all layers\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = True\n",
    "                \n",
    "                \n",
    "                # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                \n",
    "                # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "                \n",
    "                test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "                \n",
    "                \n",
    "                criterion = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
    "                optimizer = get_optimizer(optimizer_name,model.parameters(), lr=lr)\n",
    "                \n",
    "                \n",
    "                for epoch in range(start,total_epochs,step):\n",
    "                    \n",
    "                    \n",
    "                    train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                    val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                    test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "                    print(\"----------Values After Training-----------\")\n",
    "                    print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                        f\"\\nOptimizer: {optimizer_name}, \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                            f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                            f\"Train ROC AUC: {train_roc_auc if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                    print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                    print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                        f\"\\nOptimizer: {optimizer_name}, \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                                f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc if train_roc_auc is not None else 'N/A'}, \"\n",
    "                                f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                    print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                    print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                        f\"\\nOptimizer: {optimizer_name}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                                f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc if train_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    overall_result = {\n",
    "                        'Epoch': epoch ,\n",
    "                        'Batch Size': batch_size,\n",
    "                        'Learning Rate': lr,\n",
    "                        'Optimizer': optimizer_name,\n",
    "\n",
    "                        'Train Loss': round(train_loss, 4),\n",
    "                        'Test Loss': round(test_loss, 4),\n",
    "                        'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                        'Train Acc': round(train_acc, 4),\n",
    "                        'Test Acc': round(test_acc, 4),\n",
    "                        'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                        'Train Precision': round(train_precision, 4),\n",
    "                        'Test Precision': round(test_precision, 4),\n",
    "                        'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                        'Train Recall': round(train_recall, 4),\n",
    "                        'Test Recall': round(test_recall, 4),\n",
    "                        'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                        'Train F1 Score': round(train_f1, 4),\n",
    "                        'Test F1 Score': round(test_f1, 4),\n",
    "                        'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                        'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                        'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                        'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                        'Train RMSE': round(train_rmse, 4),\n",
    "                        'Test RMSE': round(test_rmse, 4),\n",
    "                        'Val RMSE': round(val_rmse, 4)\n",
    "                    }\n",
    "\n",
    "                    overall_result_file = f'../Sample testing/Test 15/Batch {batch_size} model parameter testing.csv'\n",
    "                    if not os.path.isfile(overall_result_file):\n",
    "                        pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                    else:\n",
    "                        pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "                    \n",
    "                    \n",
    "                    model_save_path = f\"../Sample testing/Test 15/Batch{batch_size}_LR{lr}_Optim{optimizer_name}.pth\"\n",
    "                    torch.save(model.state_dict(), model_save_path)\n",
    "                    print(f\"Model saved to {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_save_path = f\"../Sample testing/Test 15/Batch{batch_size}_LR{lr}_Optim{optimizer_name}.pth\"\n",
    "# torch.save(model.state_dict(), model_save_path)\n",
    "# print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = '../Sample testing/'\n",
    "\n",
    "# Count the number of subdirectories\n",
    "dir_count = sum([1 for item in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, item))])\n",
    "\n",
    "# Print the count of directories\n",
    "print(f'Number of directories in {directory_path}: {dir_count}')\n",
    "\n",
    "new_dir_path = f'../Sample testing/Test {dir_count+1}'\n",
    "\n",
    "# Check if the directory exists, and create it if it does not\n",
    "if not os.path.exists(new_dir_path):\n",
    "    os.mkdir(new_dir_path)\n",
    "    print(f'New directory created at {new_dir_path}')\n",
    "else:\n",
    "    print(f'Directory {new_dir_path} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# -------- 1. PARAMETERS --------\n",
    "dataset_path = r'../Preprocessing/New Dataset'  # Folder with subfolders dry/, oily/, normal/\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "seed = 42\n",
    "num_classes = 3  # dry, oily, normal\n",
    "\n",
    "# -------- 2. LOAD AND SPLIT DATA --------\n",
    "# Load full dataset as unbatched individual images\n",
    "full_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    image_size=img_size,\n",
    "    label_mode='int',\n",
    "    batch_size=None,  # For manual splitting\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    class_names=['dry', 'normal','oily']\n",
    ")\n",
    "\n",
    "\n",
    "# Convert dataset to list\n",
    "data_list = list(full_dataset)\n",
    "random.seed(seed)\n",
    "random.shuffle(data_list)\n",
    "\n",
    "# Manual 70/15/15 split\n",
    "total_len = len(data_list)\n",
    "train_len = int(0.7 * total_len)\n",
    "val_len = int(0.15 * total_len)\n",
    "\n",
    "train_data = data_list[:train_len]\n",
    "val_data = data_list[train_len:train_len + val_len]\n",
    "test_data = data_list[train_len + val_len:]\n",
    "\n",
    "# Convert to tf.data.Dataset\n",
    "def build_dataset(data_list, batch_size):\n",
    "    images, labels = zip(*data_list)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(images), list(labels)))\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_ds = build_dataset(train_data, batch_size)\n",
    "val_ds = build_dataset(val_data, batch_size)\n",
    "test_ds = build_dataset(test_data, batch_size)\n",
    "\n",
    "# -------- 3. BUILD MODEL (EfficientNetV2 + Custom Classifier) --------\n",
    "base_model = EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=img_size + (3,))\n",
    "base_model.trainable = True  # UnFreeze base\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "# -------- 4. TRAIN --------\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=2)\n",
    "\n",
    "# -------- 5. EVALUATE --------\n",
    "train_loss, train_acc = model.evaluate(train_ds, verbose=2)\n",
    "val_loss, val_acc = model.evaluate(val_ds, verbose=2)\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
    "\n",
    "\n",
    "# -------- 6. SAVE MODEL --------\n",
    "save_dir = '../saved_models/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model.save(os.path.join(save_dir, 'best_model.keras'))\n",
    "\n",
    "# -------- 7. EXPORT RESULTS TO CSV --------\n",
    "results = {\n",
    "    'Train Loss': round(train_loss, 4),\n",
    "    'Val Loss': round(val_loss, 4),\n",
    "    'Test Loss': round(test_loss, 4),\n",
    "    'Train Acc': round(train_acc, 4),\n",
    "    'Val Acc': round(val_acc, 4),\n",
    "    'Test Acc': round(test_acc, 4)\n",
    "}\n",
    "\n",
    "csv_file = f'../Sample testing/Test 15/Batch {batch_size} model parameter testing.csv'\n",
    "os.makedirs(os.path.dirname(csv_file), exist_ok=True)\n",
    "\n",
    "if not os.path.isfile(csv_file):\n",
    "    pd.DataFrame([results]).to_csv(csv_file, index=False)\n",
    "else:\n",
    "    pd.DataFrame([results]).to_csv(csv_file, mode='a', index=False, header=False)\n",
    "\n",
    "print(\"✅ Results saved to CSV.\")\n",
    "print(\"✅ Model saved to:\", os.path.join(save_dir, 'best_model.keras'))\n",
    "print(results)\n",
    "\n",
    "# -------- 6. OUTPUT --------\n",
    "# results = {\n",
    "#     'Train Loss': round(train_loss, 4),\n",
    "#     'Test Loss': round(test_loss, 4),\n",
    "#     'Val Loss': round(val_loss, 4),\n",
    "\n",
    "\n",
    "\n",
    "#     'Train Acc': round(train_acc, 4),\n",
    "#     'Test Acc': round(test_acc, 4),\n",
    "#     'Val Acc': round(val_acc, 4)\n",
    "# }\n",
    "\n",
    "\n",
    "# overall_result = {\n",
    "#     'Epoch': epoch ,\n",
    "#     'Batch Size': batch_size,\n",
    "#     'Learning Rate': lr,\n",
    "#     'Optimizer': optimizer_name,\n",
    "#     'Train Loss': round(train_loss, 4),\n",
    "#     'Test Loss': round(test_loss, 4),\n",
    "#     'Val Loss': round(val_loss,4),\n",
    "#     'Train Acc': round(train_acc, 4),\n",
    "#     'Test Acc': round(test_acc, 4),\n",
    "#     'Val Acc': round(val_acc, 4),\n",
    "#     'Train Precision': round(train_precision, 4),\n",
    "#     'Test Precision': round(test_precision, 4),\n",
    "#     'Val Precision': round(val_precision, 4),\n",
    "#     'Train Recall': round(train_recall, 4),\n",
    "#     'Test Recall': round(test_recall, 4),\n",
    "#     'Val Recall': round(val_recall, 4),\n",
    "#     'Train F1 Score': round(train_f1, 4),\n",
    "#     'Test F1 Score': round(test_f1, 4),\n",
    "#     'Val F1 Score': round(val_f1, 4),\n",
    "#     'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "#     'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "#     'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "#     'Train RMSE': round(train_rmse, 4),\n",
    "#     'Test RMSE': round(test_rmse, 4),\n",
    "#     'Val RMSE': round(val_rmse, 4),\n",
    "# }\n",
    "\n",
    "# overall_result_file = f'../Sample testing/Test 15/Batch {batch_size} model parameter testing.csv'\n",
    "# if not os.path.isfile(overall_result_file):\n",
    "#     pd.DataFrame([results]).to_csv(overall_result_file, index=False)\n",
    "# else:\n",
    "#     pd.DataFrame([results]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "\n",
    "# print(results)\n",
    "# model = tf.keras.models.load_model(\"../saved_models/best_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN with K folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "    \n",
    "    \n",
    "# -------- Parameters --------\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "seed = 42\n",
    "num_classes = 3\n",
    "optimizer_name = \"Adam\"\n",
    "\n",
    "\n",
    "# -------- Load Dataset as (image, label) pairs --------\n",
    "dataset_path = r'../Preprocessing/New Dataset'\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    image_size=img_size,\n",
    "    label_mode='int',\n",
    "    batch_size=None,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    class_names=['dry', 'normal','oily']\n",
    ")\n",
    "data_list = list(dataset)\n",
    "random.shuffle(data_list)\n",
    "\n",
    "# -------- Convert to numpy arrays --------\n",
    "images, labels = zip(*data_list)\n",
    "X = tf.stack(list(images))\n",
    "y = np.array(labels)\n",
    "\n",
    "# # -------- Create CSV if doesn't exist --------\n",
    "# Initialize dictionary to hold the counts\n",
    "class_names = ['dry', 'normal','oily']\n",
    "class_counts = {}\n",
    "\n",
    "# Iterate through each class (subfolder) and count the number of images\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    # Count the number of image files (assuming image files are .jpg, .jpeg, .png)\n",
    "    image_count = len([f for f in os.listdir(class_path) if f.endswith(('jpg', 'jpeg', 'png'))])\n",
    "    class_counts[class_name] = image_count\n",
    "\n",
    "# Display the class counts\n",
    "print(\"Class distribution:\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "\n",
    "# Calculate imbalance ratio (larger ratio means higher imbalance)\n",
    "imbalance_ratio = max(class_counts.values()) / min(class_counts.values())\n",
    "print(f\"Imbalance Ratio: {imbalance_ratio}\")\n",
    "\n",
    "# -------- Cross-validation loop --------\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n🌀 Fold {fold + 1}/10\")\n",
    "\n",
    "    X_train, X_test = tf.gather(X, train_idx), tf.gather(X, test_idx)\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    val_split = int(0.15 * len(X_train))\n",
    "    X_val, y_val = X_train[:val_split], y_train[:val_split]\n",
    "    X_train, y_train = X_train[val_split:], y_train[val_split:]\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "\n",
    "        base_model = EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=img_size + (3,))\n",
    "        base_model.trainable = True\n",
    "\n",
    "        model = Sequential([\n",
    "            base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dropout(0.5),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        optimizer = Adam(learning_rate=learning_rate, weight_decay=0.01)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "        class MetricsLogger(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                def get_metrics(ds):\n",
    "                    y_true = []\n",
    "                    y_pred = []\n",
    "                    for batch_x, batch_y in ds:\n",
    "                        preds = model.predict(batch_x, verbose=0)\n",
    "                        y_true.extend(batch_y.numpy())\n",
    "                        y_pred.extend(np.argmax(preds, axis=1))\n",
    "                    acc = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "                    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "                    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "                    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "                    roc_auc = roc_auc_score(y_true, y_pred) if len(set(y_true)) == 2 else None\n",
    "                    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "                    loss = model.evaluate(ds, verbose=0)[0]\n",
    "                    return loss, acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = get_metrics(train_ds)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = get_metrics(val_ds)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = get_metrics(test_ds)\n",
    "\n",
    "                overall_result = {\n",
    "                    'Epoch': epoch + 1,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': learning_rate,\n",
    "                    'Optimizer': optimizer_name,\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4),\n",
    "                }\n",
    "                \n",
    "                overall_result_file = f'../Sample testing/Test 15/Batch {batch_size} model parameter testing.csv'\n",
    "                \n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)\n",
    "\n",
    "        # -------- Train model --------\n",
    "        model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=2, callbacks=[MetricsLogger()])\n",
    "\n",
    "    # Optional: save best model per fold\n",
    "    model.save(f'../saved_models/model_fold_{fold + 1}.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Iqra Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "# === Paths ===\n",
    "input_data_path = '../Preprocessing/New Dataset'\n",
    "output_dir = '../Sample testing/Test 16/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "csv_file = os.path.join(output_dir, 'final_averaged_results_all_batches.csv')\n",
    "\n",
    "# === Hyperparameters ===\n",
    "batch_sizes = [16]\n",
    "learning_rates = [0.0001]\n",
    "optimizers_list = ['Adam']\n",
    "start, total_epochs, step, k = 100, 501, 5, 10\n",
    "\n",
    "#batch_sizes = [8,16,32,64]\n",
    "#learning_rates = [0.1 , 0.001 ,0.0001 , 0,00001]\n",
    "#optimizers_list = ['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "# === Optimizer Selector ===\n",
    "def get_optimizer(name, lr, wd=0.01):\n",
    "    if name == 'Adam':\n",
    "        return Adam(learning_rate=lr, weight_decay=wd)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {name}\")\n",
    "\n",
    "# === Load Image Paths and Labels ===\n",
    "def load_data(image_dir):\n",
    "    classes = sorted(os.listdir(image_dir))\n",
    "    images, labels = [], []\n",
    "    for label, cls in enumerate(classes):\n",
    "        cls_folder = os.path.join(image_dir, cls)\n",
    "        for fname in os.listdir(cls_folder):\n",
    "            if fname.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                images.append(os.path.join(cls_folder, fname))\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels), classes\n",
    "\n",
    "# === Image Preprocessing ===\n",
    "def preprocess_input(img_path, size=(224, 224)):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    return img / 255.0\n",
    "\n",
    "# === Build Model ===\n",
    "def create_model(num_classes):\n",
    "    base_model = EfficientNetV2B0(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# === Main Execution ===\n",
    "image_paths, labels, class_names = load_data(input_data_path)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            for epoch in range(start, total_epochs, step):\n",
    "                kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "                metrics = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "                for train_index, test_val_index in kf.split(image_paths):\n",
    "                    train_paths, test_val_paths = image_paths[train_index], image_paths[test_val_index]\n",
    "                    train_labels, test_val_labels = labels[train_index], labels[test_val_index]\n",
    "                    test_paths, val_paths, test_labels, val_labels = train_test_split(\n",
    "                        test_val_paths, test_val_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "                    x_train = np.array([preprocess_input(p) for p in train_paths])\n",
    "                    x_test = np.array([preprocess_input(p) for p in test_paths])\n",
    "                    x_val = np.array([preprocess_input(p) for p in val_paths])\n",
    "\n",
    "                    y_train = tf.keras.utils.to_categorical(train_labels, num_classes=len(class_names))\n",
    "                    y_test = tf.keras.utils.to_categorical(test_labels, num_classes=len(class_names))\n",
    "                    y_val = tf.keras.utils.to_categorical(val_labels, num_classes=len(class_names))\n",
    "\n",
    "                    model = create_model(len(class_names))\n",
    "                    optimizer = get_optimizer(optimizer_name, lr)\n",
    "                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    model.fit(x_train, y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "                    def evaluate(x, y_true):\n",
    "                        y_pred = model.predict(x, verbose=0)\n",
    "                        y_true_cls = np.argmax(y_true, axis=1)\n",
    "                        y_pred_cls = np.argmax(y_pred, axis=1)\n",
    "                        return {\n",
    "                            'loss': model.evaluate(x, y_true, verbose=0)[0],\n",
    "                            'acc': accuracy_score(y_true_cls, y_pred_cls),\n",
    "                            'precision': precision_score(y_true_cls, y_pred_cls, average='weighted'),\n",
    "                            'recall': recall_score(y_true_cls, y_pred_cls, average='weighted'),\n",
    "                            'f1': f1_score(y_true_cls, y_pred_cls, average='weighted'),\n",
    "                            'roc_auc': roc_auc_score(y_true, y_pred, multi_class='ovr'),\n",
    "                            'rmse': mean_squared_error(y_true, y_pred, squared=False)\n",
    "                        }\n",
    "\n",
    "                    metrics['train'].append(evaluate(x_train, y_train))\n",
    "                    metrics['test'].append(evaluate(x_test, y_test))\n",
    "                    metrics['val'].append(evaluate(x_val, y_val))\n",
    "\n",
    "                def average_metrics(metric_list):\n",
    "                    return {key: round(np.mean([m[key] for m in metric_list]), 4) for key in metric_list[0]}\n",
    "\n",
    "                avg_train = average_metrics(metrics['train'])\n",
    "                avg_test = average_metrics(metrics['test'])\n",
    "                avg_val = average_metrics(metrics['val'])\n",
    "\n",
    "                result = {\n",
    "                    'Epoch': epoch, 'Batch Size': batch_size, 'Learning Rate': lr, 'Optimizer': optimizer_name,\n",
    "                    'Train Loss': avg_train['loss'], 'Test Loss': avg_test['loss'], 'Val Loss': avg_val['loss'],\n",
    "                    'Train Acc': avg_train['acc'], 'Test Acc': avg_test['acc'], 'Val Acc': avg_val['acc'],\n",
    "                    'Train Precision': avg_train['precision'], 'Test Precision': avg_test['precision'], 'Val Precision': avg_val['precision'],\n",
    "                    'Train Recall': avg_train['recall'], 'Test Recall': avg_test['recall'], 'Val Recall': avg_val['recall'],\n",
    "                    'Train F1 Score': avg_train['f1'], 'Test F1 Score': avg_test['f1'], 'Val F1 Score': avg_val['f1'],\n",
    "                    'Train ROC AUC': avg_train['roc_auc'], 'Test ROC AUC': avg_test['roc_auc'], 'Val ROC AUC': avg_val['roc_auc'],\n",
    "                    'Train RMSE': avg_train['rmse'], 'Test RMSE': avg_test['rmse'], 'Val RMSE': avg_val['rmse']\n",
    "                }\n",
    "\n",
    "                pd.DataFrame([result]).to_csv(csv_file, mode='a', header=not os.path.exists(csv_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
