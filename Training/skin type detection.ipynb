{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Noisy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_exts = ['jpg', 'jpeg', 'png', 'bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "\n",
    "data_dir = '../Preprocessing/Processed_Images'\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(image_path)    # print the path of the image with unknown extension\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image:\" .format(image_path))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [16,32]\n",
    "for size in batch_size:\n",
    "   data = tf.keras.utils.image_dataset_from_directory('../Preprocessing/Processed_Images', batch_size=size, image_size=(256, 256), shuffle=True) #Data pipeline\n",
    "\n",
    "class_names = data.class_names #get the class names\n",
    "print(class_names)\n",
    "\n",
    "data_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "\n",
    "batch = data_iterator.next() #get the next batch of data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape # shape of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1] # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "rows = 4\n",
    "cols = 8\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20, 12))\n",
    "fig.suptitle('Sample Images with Class Labels', fontsize=16)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display images in grid\n",
    "for idx, (image, label) in enumerate(zip(batch[0][:32], batch[1][:32])):\n",
    "    # Get class name from label index\n",
    "    class_name = class_names[label]\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx].imshow(image.astype(\"uint8\"))\n",
    "    axes[idx].set_title(f'{class_name}', fontsize=8)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Add color-coded legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=f'C{i}', markersize=10, \n",
    "                             label=name) for i, name in enumerate(class_names)]\n",
    "fig.legend(handles=legend_elements, loc='center right')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)  # Make room for legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y : ((x/255),y)) #normalizing the data  \n",
    "scaled_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "batch = scaled_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].max() #max value in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.7) #70% of the data for training\n",
    "val_size = int(len(data) * 0.2) #20% of the data for validation\n",
    "test_size = int(len(data) * 0.1) #10% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size) #take the first 70% of the data for training\n",
    "val = data.skip(train_size).take(val_size) #skip the first 70% and take the next 20% for validation\n",
    "test = data.skip(train_size + val_size).take(test_size) #skip the first 90% and take the next 10% for testing\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomTranslation, RandomContrast, RandomCrop\n",
    "# filter size = 3x3\n",
    "# input shape = 256x256x3\n",
    "# stride = 1\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = batch[0].shape[0]\n",
    "model = Sequential() #initialize the model\n",
    "\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),         # Flip images both horizontally and vertically\n",
    "    RandomRotation(0.4),                           # Rotate images up to 40% in both directions\n",
    "    RandomZoom(height_factor=(-0.2, 0.2),          # Random zoom in/out\n",
    "               width_factor=(-0.2, 0.2)),\n",
    "    RandomTranslation(height_factor=0.2,           # Translate images up to 20% in height\n",
    "                      width_factor=0.2),           # Translate images up to 20% in width\n",
    "    RandomContrast(0.2),                           # Adjust contrast randomly\n",
    "    RandomCrop(IMAGE_SIZE - 20, IMAGE_SIZE - 20),  # Crop random parts of the image\n",
    "    tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE)  # Resize back to target size\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what is the expected dimension order for channel\n",
    "from tensorflow.keras import backend as k\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "batch_input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "chanDim = -1\n",
    "if k.image_data_format() == \"channels_first\":\n",
    "    input_shape = (CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    batch_input_shape = (BATCH_SIZE, CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    chanDim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "model_dir = '../saved_models'\n",
    "log_dir = os.path.join(model_dir, 'logs')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(model_dir, 'best_model.keras'),\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "final_model_path = os.path.join(model_dir, 'final_model.keras')\n",
    "model.save(final_model_path)\n",
    "print(f\"Model saved to {final_model_path}\")\n",
    "from matplotlib import pyplot as plt\n",
    "rows = 4\n",
    "cols = 8\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20, 12))\n",
    "fig.suptitle('Sample Images with Class Labels', fontsize=16)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display images in grid\n",
    "for idx, (image, label) in enumerate(zip(batch[0][:32], batch[1][:32])):\n",
    "    # Get class name from label index\n",
    "    class_name = class_names[label]\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx].imshow(image.astype(\"uint8\"))\n",
    "    axes[idx].set_title(f'{class_name}', fontsize=8)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Add color-coded legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=f'C{i}', markersize=10, \n",
    "                             label=name) for i, name in enumerate(class_names)]\n",
    "fig.legend(handles=legend_elements, loc='center right')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)  # Make room for legend\n",
    "plt.show()\n",
    "\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "train = data.take(train_size) #take the first 70% of the data for training\n",
    "val = data.skip(train_size).take(val_size) #skip the first 70% and take the next 20% for validation\n",
    "test = data.skip(train_size + val_size).take(test_size) #skip the first 90% and take the next 10% for testing\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "img_exts = ['jpg', 'jpeg', 'png', 'bmp']\n",
    "data_dir = 'skinType'\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(image_path)    # print the path of the image with unknown extension\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image:\" .format(image_path))\n",
    "batch_size = [16,32]\n",
    "for size in batch_size:\n",
    "   data = tf.keras.utils.image_dataset_from_directory('skinType', batch_size=size, image_size=(256, 256), shuffle=True) #Data pipeline\n",
    "\n",
    "class_names = data.class_names #get the class names\n",
    "print(class_names)\n",
    "\n",
    "data_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "\n",
    "batch = data_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].shape # shape of the batch\n",
    "       \n",
    "batch[1] # labels\n",
    "\n",
    "data = data.map(lambda x,y : ((x/255),y)) #normalizing the data  \n",
    "scaled_iterator = data.as_numpy_iterator() #allows us to access Data pipeline\n",
    "batch = scaled_iterator.next() #get the next batch of data\n",
    "\n",
    "batch[0].max() #max value in the batch\n",
    "\n",
    "len(data)\n",
    "\n",
    "train_size = int(len(data) * 0.7) #70% of the data for training\n",
    "val_size = int(len(data) * 0.2) #20% of the data for validation\n",
    "test_size = int(len(data) * 0.1) #10% of the data for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from vit_pytorch import ViT\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "#unprocessed Data\n",
    "# dataset_path = '../skinType' \n",
    "\n",
    "#preprocessed Data\n",
    "dataset_path = '../Preprocessing/Processed_Images' \n",
    "\n",
    "# Define hyperparameters\n",
    "batch_sizes = [4 , 8, 16, 32,64]\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.00001]\n",
    "optimizers_list = ['SGD', 'Adam', 'RMSprop', 'AdamW']\n",
    "total_epochs = 100\n",
    "num_classes = 3  # Dry, Normal, Oily skin types\n",
    "\n",
    "# Load Dataset\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Dataset Path\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Split Dataset into Train, Validation, and Test\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Function to initialize the model\n",
    "def create_vit_model():\n",
    "    # model = ViT(\n",
    "    #     image_size=224,\n",
    "    #     patch_size=32,\n",
    "    #     num_classes=num_classes,  # 3 classes: dry, normal, oily\n",
    "    #     dim=64,                   # model embedding dimension\n",
    "    #     depth=6,                  # number of transformer layers\n",
    "    #     heads=8,                  # number of heads in multi-head attention\n",
    "    #     mlp_dim=128,              # hidden dimension in MLP head\n",
    "    #     dropout=0.1,\n",
    "    #     emb_dropout=0.1\n",
    "    # )\n",
    "    \n",
    "    \n",
    "    model = ViT(\n",
    "        image_size=224,\n",
    "        patch_size=16,\n",
    "        num_classes=num_classes,\n",
    "        dim=1024,  # Increased dimension\n",
    "        depth=12,  # More layers\n",
    "        heads=16,  # More attention heads\n",
    "        mlp_dim=2048,\n",
    "        dropout=0.2,  # Slightly higher dropout\n",
    "        emb_dropout=0.2,\n",
    "        pool='cls'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Optimizer choices\n",
    "def get_optimizer(optimizer_name, model_params, lr):\n",
    "    if optimizer_name == 'SGD':\n",
    "        return optim.SGD(model_params, lr=lr, momentum=0.9)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        return optim.Adam(model_params, lr=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        return optim.RMSprop(model_params, lr=lr)\n",
    "    elif optimizer_name == 'AdamW':\n",
    "        return optim.AdamW(model_params, lr=lr)\n",
    "\n",
    "# Training Function\n",
    "# def train_model(model, loader, optimizer, criterion, device):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     all_preds, all_labels = [], []\n",
    "    \n",
    "#     for inputs, labels in loader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#         # Record predictions\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         all_preds.extend(preds.cpu().numpy())\n",
    "#         all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     accuracy = accuracy_score(all_labels, all_preds)\n",
    "#     return running_loss / len(loader), accuracy, accuracy, precision, recall, f1, roc_auc, rmse \n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)  # Get probabilities\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f\"{name} - grad mean: {param.grad.mean():.4f}, max: {param.grad.max():.4f}\")\n",
    "        #     else:\n",
    "        #         print(f\"{name} - NO GRADIENTS!\")\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Record predictions\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    try:\n",
    "        unique_classes = np.unique(all_labels)\n",
    "        if len(unique_classes) == num_classes:\n",
    "            roc_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr', average='weighted')\n",
    "        else:\n",
    "            roc_auc = None\n",
    "    except ValueError:\n",
    "        roc_auc = None  # Handle cases where ROC-AUC cannot be computed\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "\n",
    "    return running_loss / len(loader), accuracy, precision, recall, f1, roc_auc, rmse  \n",
    "\n",
    "# Validation and Test Function\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Record predictions\n",
    "             # Record predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        # Ensure all classes are represented before computing ROC-AUC\n",
    "        unique_classes = np.unique(all_labels)\n",
    "        if len(unique_classes) == num_classes:\n",
    "            roc_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr', average='weighted')\n",
    "        else:\n",
    "            print(\"Warning: Not all classes are present in the evaluation set. Skipping ROC-AUC calculation.\")\n",
    "            roc_auc = None\n",
    "    except ValueError:\n",
    "        roc_auc = None  # Handle cases where ROC-AUC cannot be computed\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "    \n",
    "    return running_loss / len(loader), accuracy, precision, recall, f1, roc_auc, rmse \n",
    "\n",
    "\n",
    "# Function to print weights of the model\n",
    "def print_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"Layer: {name} | Weights: {param.data}\")\n",
    "\n",
    "# Main training loop\n",
    "\n",
    "def train_and_evaluate(batch_size, lr, optimizer_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model, Optimizer, Criterion\n",
    "    model = create_vit_model().to(device)\n",
    "    optimizer = get_optimizer(optimizer_name, model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "   \n",
    "      # Training\n",
    "    for epoch in range(total_epochs):\n",
    "        # print(\"\\n\\n-------------------------Checking Weights in Each Iteration----------------------------\")\n",
    "        # print(\"Initial Weights:\")\n",
    "        # print_weights(model)\n",
    "        # print(\"\\n\\n-------------------------Checking Weights in Each Iteration-----------------------------\")\n",
    "  \n",
    "        train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "        test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "        \n",
    "        print(\"----------Values After Training-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "              f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                   f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                   f\"Train ROC AUC: {train_roc_auc:.4f}, Train RMSE: {train_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "              f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                    f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, \"\n",
    "                    f\"Val RMSE: {val_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "              f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                    f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "                \n",
    "        \n",
    "        # Save the trained model\n",
    "        # os.makedirs('../saved_models', exist_ok=True)\n",
    "        # model_save_path = f\"../saved_models/vit_model_bs{batch_size}_lr{lr}_{optimizer_name}.pth\"\n",
    "        # torch.save(model.state_dict(), model_save_path)\n",
    "        # print(f\"Model saved to {model_save_path}\") # Save results to CSV\n",
    "        \n",
    "        #Saving Training data\n",
    "        train_result = {\n",
    "            'Epoch': epoch + 1,\n",
    "            'Batch Size': batch_size,\n",
    "            'Learning Rate': round(lr, 4),\n",
    "            'Optimizer': optimizer_name,\n",
    "            'Train Loss':round(train_loss, 4),\n",
    "            'Train Acc': round(train_acc, 4),\n",
    "            'Train Precision': round(train_precision, 4),\n",
    "            'Train Recall': round(train_recall, 4),\n",
    "            'Train F1 Score': round(train_f1, 4),\n",
    "            'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,  # Handle None case\n",
    "            'Train RMSE': round(train_rmse, 4)\n",
    "        }\n",
    "        \n",
    "        #Saving Testing data\n",
    "        test_result = {\n",
    "            'Epoch': epoch + 1,\n",
    "            'Batch Size': batch_size,\n",
    "            'Learning Rate': round(lr, 4),\n",
    "            'Optimizer': optimizer_name,\n",
    "            'Test Loss':round(test_loss, 4),\n",
    "            'Test Acc': round(test_acc, 4),\n",
    "            'Test Precision': round(test_precision, 4),\n",
    "            'Test Recall': round(test_recall, 4),\n",
    "            'Test F1 Score': round(test_f1, 4),\n",
    "            'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,  # Handle None case\n",
    "            'Test RMSE': round(test_rmse, 4)\n",
    "        }\n",
    "        \n",
    "        #Saving Val data\n",
    "        val_result = {\n",
    "            'Epoch': epoch + 1,\n",
    "            'Batch Size': batch_size,\n",
    "            'Learning Rate': round(lr, 4),\n",
    "            'Optimizer': optimizer_name,\n",
    "            'Val Loss':round(val_loss, 4),\n",
    "            'Val Acc': round(val_acc, 4),\n",
    "            'Val Precision': round(val_precision, 4),\n",
    "            'Val Recall': round(val_recall, 4),\n",
    "            'Val F1 Score': round(val_f1, 4),\n",
    "            'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,  # Handle None case\n",
    "            'Val RMSE': round(val_rmse, 4)\n",
    "        }\n",
    "\n",
    "\n",
    "        # Append to CSV\n",
    "        train_results_file = 'train_results.csv'\n",
    "        test_results_file = 'test_results.csv'\n",
    "        val_results_file = 'val_results.csv'\n",
    "        \n",
    "        if not os.path.isfile(train_results_file) or not os.path.isfile(test_results_file) or not os.path.isfile(val_results_file):\n",
    "            pd.DataFrame([train_result]).to_csv(train_results_file, index=False)\n",
    "            pd.DataFrame([test_result]).to_csv(test_results_file, index=False)\n",
    "            pd.DataFrame([val_result]).to_csv(val_results_file, index=False)\n",
    "            \n",
    "        else:\n",
    "            pd.DataFrame([train_result]).to_csv(train_results_file, mode='a', header=False, index=False)\n",
    "            pd.DataFrame([test_result]).to_csv(test_results_file, mode='a', header=False, index=False)\n",
    "            pd.DataFrame([val_result]).to_csv(val_results_file, mode='a', header=False, index=False)\n",
    "        \n",
    "        \n",
    "\n",
    "    # # Convert results into DataFrame\n",
    "    # df_results = pd.DataFrame([result])\n",
    "\n",
    "    # # 🔹 Plot results\n",
    "    # metrics = ['Test Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'RMSE']\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # for i, metric in enumerate(metrics, 1):\n",
    "    #     plt.subplot(2, 3, i)\n",
    "    #     sns.boxplot(data=df_results, x='Optimizer', y=metric, hue='Optimizer', palette=\"Set2\", legend=False)\n",
    "\n",
    "    #     plt.xticks(rotation=45)\n",
    "    #     plt.title(metric)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "                \n",
    "    # return test_acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "# Grid search across all parameters\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "                # test_metrics = \n",
    "                train_and_evaluate(batch_size, lr, optimizer_name)\n",
    "                # print(f\"Final Test Metrics with Batch Size {batch_size}, LR {lr}, Optimizer {optimizer_name}: {test_metrics}\")\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from vit_pytorch import ViT\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Hyperparameter ranges\n",
    "batch_sizes = [4, 8, 16, 32, 64]\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.00001]\n",
    "optimizers_list = ['SGD', 'Adam', 'RMSprop', 'AdamW']\n",
    "total_epochs = 100\n",
    "num_classes = 3  # Dry, Normal, Oily skin types\n",
    "\n",
    "# Dataset Path\n",
    "dataset_path = '../Preprocessing/Processed_Images'\n",
    "\n",
    "# Enhanced data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path)\n",
    "\n",
    "# Split Dataset\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "# Create datasets with transforms\n",
    "train_dataset = datasets.ImageFolder(root=dataset_path, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=dataset_path, transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root=dataset_path, transform=val_test_transform)\n",
    "\n",
    "# Apply the same splits\n",
    "train_dataset, _, _ = random_split(train_dataset, [train_size, len(train_dataset)-train_size, 0])\n",
    "_, val_dataset, _ = random_split(val_dataset, [len(val_dataset)-val_size, val_size, 0])\n",
    "_, _, test_dataset = random_split(test_dataset, [len(test_dataset)-test_size, 0, test_size])\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = Counter([label for _, label in train_dataset])\n",
    "total = sum(class_counts.values())\n",
    "class_weights = torch.tensor([total/class_counts[i] for i in range(len(class_counts))]).float()\n",
    "\n",
    "# Enhanced ViT Model\n",
    "def create_vit_model():\n",
    "    model = ViT(\n",
    "        image_size=224,\n",
    "        patch_size=16,\n",
    "        num_classes=num_classes,\n",
    "        dim=768,\n",
    "        depth=6,\n",
    "        heads=8,\n",
    "        mlp_dim=2048,\n",
    "        dropout=0.1,\n",
    "        emb_dropout=0.1,\n",
    "        pool='cls'\n",
    "    )\n",
    "    \n",
    "    # Initialize weights\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.ones_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "    \n",
    "    model.apply(init_weights)\n",
    "    return model\n",
    "\n",
    "# Get optimizer\n",
    "def get_optimizer(optimizer_name, model_params, lr):\n",
    "    if optimizer_name == 'SGD':\n",
    "        return optim.SGD(model_params, lr=lr, momentum=0.9, nesterov=True)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        return optim.Adam(model_params, lr=lr, betas=(0.9, 0.999))\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        return optim.RMSprop(model_params, lr=lr, alpha=0.99)\n",
    "    elif optimizer_name == 'AdamW':\n",
    "        return optim.AdamW(model_params, lr=lr, weight_decay=0.01)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.detach().cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    loss = running_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        roc_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr', average='weighted')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "    \n",
    "    return loss, accuracy, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    loss = running_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        roc_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr', average='weighted')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "    \n",
    "    return loss, accuracy, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "# Main training loop\n",
    "def train_and_evaluate(batch_size, lr, optimizer_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nTraining with batch_size={batch_size}, lr={lr}, optimizer={optimizer_name}\")\n",
    "    \n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Model, Optimizer, Criterion\n",
    "    model = create_vit_model().to(device)\n",
    "    optimizer = get_optimizer(optimizer_name, model.parameters(), lr)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "        # Train\n",
    "        train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(\n",
    "            model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(\n",
    "            model, val_loader, criterion, device)\n",
    "        \n",
    "        # Test\n",
    "        test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(\n",
    "            model, test_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Print all values\n",
    "        print(\"----------Values After Training-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "              f\"\\nOptimizer: {optimizer_name} \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                   f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                   f\"Train ROC AUC: {train_roc_auc:.4f if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "              f\"\\nOptimizer: {optimizer_name} \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                    f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f if val_roc_auc is not None else 'N/A'}, \"\n",
    "                    f\"Val RMSE: {val_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "        print(f\"\\nEpoch: [{epoch+1}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "              f\"\\nOptimizer: {optimizer_name} Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                    f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc:.4f if test_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "        \n",
    "        # Save all data\n",
    "        train_result = {\n",
    "            'Epoch': epoch + 1,\n",
    "            'Batch Size': batch_size,\n",
    "            'Learning Rate': round(lr, 4),\n",
    "            'Optimizer': optimizer_name,\n",
    "            'Train Loss': round(train_loss, 4),\n",
    "            'Train Acc': round(train_acc, 4),\n",
    "            'Train Precision': round(train_precision, 4),\n",
    "            'Train Recall': round(train_recall, 4),\n",
    "            'Train F1 Score': round(train_f1, 4),\n",
    "            'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "            'Train RMSE': round(train_rmse, 4)\n",
    "        }\n",
    "        \n",
    "        test_result = {\n",
    "            'Epoch': epoch + 1,\n",
    "            'Batch Size': batch_size,\n",
    "            'Learning Rate': round(lr, 4),\n",
    "            'Optimizer': optimizer_name,\n",
    "            'Test Loss': round(test_loss, 4),\n",
    "            'Test Acc': round(test_acc, 4),\n",
    "            'Test Precision': round(test_precision, 4),\n",
    "            'Test Recall': round(test_recall, 4),\n",
    "            'Test F1 Score': round(test_f1, 4),\n",
    "            'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "            'Test RMSE': round(test_rmse, 4)\n",
    "        }\n",
    "        \n",
    "        val_result = {\n",
    "            'Epoch': epoch + 1,\n",
    "            'Batch Size': batch_size,\n",
    "            'Learning Rate': round(lr, 4),\n",
    "            'Optimizer': optimizer_name,\n",
    "            'Val Loss': round(val_loss, 4),\n",
    "            'Val Acc': round(val_acc, 4),\n",
    "            'Val Precision': round(val_precision, 4),\n",
    "            'Val Recall': round(val_recall, 4),\n",
    "            'Val F1 Score': round(val_f1, 4),\n",
    "            'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "            'Val RMSE': round(val_rmse, 4)\n",
    "        }\n",
    "\n",
    "        # Append to CSV\n",
    "        train_results_file = 'train_results.csv'\n",
    "        test_results_file = 'test_results.csv'\n",
    "        val_results_file = 'val_results.csv'\n",
    "        \n",
    "        if not os.path.isfile(train_results_file):\n",
    "            pd.DataFrame([train_result]).to_csv(train_results_file, index=False)\n",
    "        else:\n",
    "            pd.DataFrame([train_result]).to_csv(train_results_file, mode='a', header=False, index=False)\n",
    "            \n",
    "        if not os.path.isfile(test_results_file):\n",
    "            pd.DataFrame([test_result]).to_csv(test_results_file, index=False)\n",
    "        else:\n",
    "            pd.DataFrame([test_result]).to_csv(test_results_file, mode='a', header=False, index=False)\n",
    "            \n",
    "        if not os.path.isfile(val_results_file):\n",
    "            pd.DataFrame([val_result]).to_csv(val_results_file, index=False)\n",
    "        else:\n",
    "            pd.DataFrame([val_result]).to_csv(val_results_file, mode='a', header=False, index=False)\n",
    "    \n",
    "    return {\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': lr,\n",
    "        'optimizer': optimizer_name,\n",
    "        'best_val_acc': val_acc,\n",
    "        'best_test_acc': test_acc\n",
    "    }\n",
    "\n",
    "# Grid search\n",
    "if __name__ == \"__main__\":\n",
    "    results = []\n",
    "    for batch_size in batch_sizes:\n",
    "        for lr in learning_rates:\n",
    "            for optimizer_name in optimizers_list:\n",
    "                try:\n",
    "                    result = train_and_evaluate(batch_size, lr, optimizer_name)\n",
    "                    results.append(result)\n",
    "                    print(f\"\\nCompleted training with: batch_size={batch_size}, lr={lr}, optimizer={optimizer_name}\")\n",
    "                    print(f\"Best Val Acc: {result['best_val_acc']:.4f}, Best Test Acc: {result['best_test_acc']:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed for batch_size={batch_size}, lr={lr}, optimizer={optimizer_name}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    # Save summary of all runs\n",
    "    pd.DataFrame(results).to_csv('training_summary.csv', index=False)\n",
    "    print(\"\\nTraining completed! Results saved to:\")\n",
    "    print(\"- train_results.csv\")\n",
    "    print(\"- val_results.csv\")\n",
    "    print(\"- test_results.csv\")\n",
    "    print(\"- training_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
