{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322af318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet stats\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = ImageFolder(root=r'C:\\Users\\shazi\\OneDrive\\Desktop\\VS Code\\fyp\\skintypepatches 128x128', transform=train_transform)\n",
    "val_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Replace transform for validation\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = dataset.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64261a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=len(class_names))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ce48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efae06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "\n",
    "    return total_loss / len(loader), correct.double() / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels.data)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(loader), correct.double() / len(loader.dataset), y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8911cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc, y_true, y_pred = evaluate(model, val_loader, criterion)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae59eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"vit_model_cip.pth\")\n",
    "#add the weight saving path here #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4950a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Dataset path\n",
    "DATA_DIR = \"Preprocessing/skintypepatches 224x224\"\n",
    "\n",
    "# ImageNet mean and std\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Strong data augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(300, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(25),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])\n",
    "\n",
    "# Dataset loading\n",
    "full_dataset = datasets.ImageFolder(DATA_DIR, transform=train_transforms)\n",
    "num_classes = len(full_dataset.classes)\n",
    "\n",
    "# Dataset split\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    full_dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Apply validation/test transforms\n",
    "val_ds.dataset.transform = val_test_transforms\n",
    "test_ds.dataset.transform = val_test_transforms\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "# EfficientNetB3 model\n",
    "model = models.efficientnet_b3(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Class weights for imbalance handling\n",
    "y_train = [label for _, label in train_ds]\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.arange(num_classes), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Loss, optimizer, scheduler\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Early stopping setup\n",
    "best_acc = 0\n",
    "patience, max_patience = 0, 5\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, epochs=25):\n",
    "    global best_acc, patience\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: Val Accuracy = {acc:.4f}, Loss = {total_loss:.4f}\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), \"best_effnet_model.pth\")\n",
    "            print(\"✅ Model saved\")\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= max_patience:\n",
    "                print(\"🛑 Early stopping triggered\")\n",
    "                break\n",
    "    return best_acc\n",
    "\n",
    "best_val_acc = train_model(model, train_loader, val_loader)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"best_effnet_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, true_labels):\n",
    "    y_pred, y_probs = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, 1)\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(true_labels, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, y_pred, average='macro')\n",
    "    auc = roc_auc_score(label_binarize(true_labels, classes=range(num_classes)), y_probs, multi_class='ovr')\n",
    "    return acc, precision, recall, f1, auc\n",
    "\n",
    "# Get labels\n",
    "y_val = [label for _, label in val_ds]\n",
    "y_test = [label for _, label in test_ds]\n",
    "\n",
    "# Final evaluations\n",
    "val_metrics = evaluate(model, val_loader, y_val)\n",
    "test_metrics = evaluate(model, test_loader, y_test)\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Split\": [\"Validation\", \"Test\"],\n",
    "    \"Accuracy\": [val_metrics[0], test_metrics[0]],\n",
    "    \"Precision\": [val_metrics[1], test_metrics[1]],\n",
    "    \"Recall\": [val_metrics[2], test_metrics[2]],\n",
    "    \"F1 Score\": [val_metrics[3], test_metrics[3]],\n",
    "    \"AUC-ROC\": [val_metrics[4], test_metrics[4]],\n",
    "})\n",
    "\n",
    "metrics_df.to_csv(\"efficientnetb3_skin_metrics.csv\", index=False)\n",
    "print(\"📈 Metrics saved to efficientnetb3_skin_metrics.csv\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34362ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Directory paths\n",
    "SOURCE_TRAIN_DIR = \"Preprocessing/skintypepatches 128x128\"\n",
    "SOURCE_TEST_DIR = \"Preprocessing/skintypepatches 128x128\"\n",
    "COMBINED_DIR = \"/kaggle/working/combined\"\n",
    "TEST_DIR = \"/kaggle/working/test\"\n",
    "TRAIN_DIR = \"/kaggle/working/train\"\n",
    "VAL_DIR = \"/kaggle/working/val\"\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [COMBINED_DIR, TEST_DIR, TRAIN_DIR, VAL_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "def is_valid_image(file_path):\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        img.verify()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def copy_images(source_dir, dest_dir):\n",
    "    for subfolder in os.listdir(source_dir):\n",
    "        full_path = os.path.join(source_dir, subfolder)\n",
    "        for img in os.listdir(full_path):\n",
    "            img_path = os.path.join(full_path, img)\n",
    "            if is_valid_image(img_path):\n",
    "                dest_folder = os.path.join(dest_dir, subfolder)\n",
    "                os.makedirs(dest_folder, exist_ok=True)\n",
    "                shutil.copy(img_path, os.path.join(dest_folder, img))\n",
    "\n",
    "# Copy images to combined directory\n",
    "for source_dir in [SOURCE_TRAIN_DIR, SOURCE_TEST_DIR]:\n",
    "    copy_images(source_dir, COMBINED_DIR)\n",
    "\n",
    "def split_data(combined_dir, test_dir, train_dir, val_dir, test_size=20, val_split=0.2):\n",
    "    all_combined_images = []\n",
    "    for subfolder in os.listdir(combined_dir):\n",
    "        subfolder_path = os.path.join(combined_dir, subfolder)\n",
    "        all_combined_images += [os.path.join(subfolder_path, img) for img in os.listdir(subfolder_path)]\n",
    "\n",
    "    random.shuffle(all_combined_images)\n",
    "\n",
    "    test_images = random.sample(all_combined_images, test_size)\n",
    "    for img_path in test_images:\n",
    "        dest_folder = os.path.join(test_dir, os.path.basename(os.path.dirname(img_path)))\n",
    "        os.makedirs(dest_folder, exist_ok=True)\n",
    "        shutil.move(img_path, os.path.join(dest_folder, os.path.basename(img_path)))\n",
    "        all_combined_images.remove(img_path)\n",
    "\n",
    "    split_index = int((1 - val_split) * len(all_combined_images))\n",
    "    train_images = all_combined_images[:split_index]\n",
    "    val_images = all_combined_images[split_index:]\n",
    "\n",
    "    for image_list, folder in [(train_images, train_dir), (val_images, val_dir)]:\n",
    "        for img_path in image_list:\n",
    "            dest_folder = os.path.join(folder, os.path.basename(os.path.dirname(img_path)))\n",
    "            os.makedirs(dest_folder, exist_ok=True)\n",
    "            shutil.copy(img_path, os.path.join(dest_folder, os.path.basename(img_path)))\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "split_data(COMBINED_DIR, TEST_DIR, TRAIN_DIR, VAL_DIR)\n",
    "\n",
    "def load_and_visualize_data(data_directory, num_images_per_subfolder=4):\n",
    "    class_labels = os.listdir(data_directory)\n",
    "    fig, axes = plt.subplots(len(class_labels), num_images_per_subfolder, figsize=(10, 10))\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        class_dir = os.path.join(data_directory, class_label)\n",
    "        image_paths = [os.path.join(class_dir, img) for img in os.listdir(class_dir)[:num_images_per_subfolder]]\n",
    "        images = [plt.imread(img_path) for img_path in image_paths]\n",
    "        for j, ax in enumerate(axes[i]):\n",
    "            img = images[j]\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(class_label)\n",
    "            ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize training data\n",
    "load_and_visualize_data(TRAIN_DIR)\n",
    "\n",
    "# Data augmentation and transformation\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomAffine(degrees=0, shear=10),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "training_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=augmentations)\n",
    "validation_dataset = datasets.ImageFolder(root=VAL_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model definition\n",
    "model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "num_classes = 4\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier.in_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Training and validation loop\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10):\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_correct, train_total, total_loss = 0, 0, 0\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        print(f\"[{epoch+1}/{epochs}] Train Loss: {total_loss/len(train_loader):.4f} | Accuracy: {train_correct/train_total:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_correct, val_total, val_loss = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        acc = val_correct / val_total\n",
    "        print(f\"Validation Loss: {val_loss/len(val_loader):.4f} | Accuracy: {acc:.4f}\")\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), \"efficientnet_b3_best.pth\")\n",
    "\n",
    "# Train and validate the model\n",
    "train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, EPOCHS)\n",
    "\n",
    "# Load the best model and evaluate\n",
    "model.load_state_dict(torch.load(\"efficientnet_b3_best.pth\"))\n",
    "model.eval()\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    all_predictions, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_predictions.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return all_predictions, all_labels\n",
    "\n",
    "all_predictions, all_labels = evaluate_model(model, val_loader)\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(all_labels, all_predictions)\n",
    "prec = precision_score(all_labels, all_predictions, average='weighted')\n",
    "rec = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "df_cm = pd.DataFrame(cm, index=training_dataset.classes, columns=training_dataset.classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Test data transformation and prediction\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class_labels = ['oily','normal','dry']\n",
    "\n",
    "def predict_and_visualize_test_images(test_dir, model, class_labels, num_images_per_class=3):\n",
    "    images = []\n",
    "    for class_name in os.listdir(test_dir):\n",
    "        class_path = os.path.join(test_dir, class_name)\n",
    "        for img_name in os.listdir(class_path)[:num_images_per_class]:\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = test_transform(img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(img_tensor).argmax(1).item()\n",
    "            label = class_labels[pred]\n",
    "            correct = \"Correct\" if label == class_name else \"Wrong\"\n",
    "            images.append((img, label, correct))\n",
    "    return images\n",
    "\n",
    "images = predict_and_visualize_test_images(TEST_DIR, model, class_labels)\n",
    "\n",
    "# Visualize test predictions\n",
    "rows = int(np.ceil(len(images) / 3))\n",
    "fig, axs = plt.subplots(rows, 3, figsize=(15, 5 * rows))\n",
    "for i in range(rows):\n",
    "    for j in range(3):\n",
    "        idx = i * 3 + j\n",
    "        if idx < len(images):\n",
    "            img, label, result = images[idx]\n",
    "            axs[i, j].imshow(img)\n",
    "            axs[i, j].set_title(f\"{label} ({result})\")\n",
    "            axs[i, j].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0a577",
   "metadata": {},
   "source": [
    "Batch 8 all param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e94a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, root_mean_squared_error\n",
    "from torch_optimizer import Lamb  \n",
    "import clip\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import SGD\n",
    "from pytorch_lamb import Lamb\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "batch_sizes = [8]\n",
    "learning_rates = [0.1,0.01,0.001,0.0001,0.00001]\n",
    "optimizers_list = ['LAMB', 'AdamW', 'SGD', 'RAdam']\n",
    "num_classes=3\n",
    "total_epochs = 501\n",
    "start=100\n",
    "step=5\n",
    "\n",
    "\n",
    "\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
    "                         (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \"Preprocessing/stage2patches\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for param in clip_model.visual.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "class CLIPSkinClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super(CLIPSkinClassifier, self).__init__()\n",
    "        self.encoder = clip_model.visual\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_optimizer(optimizer_name, model_params, lr,weight_decay=0.001):\n",
    "    if optimizer_name == 'AdamW':\n",
    "        return AdamW(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'LAMB':\n",
    "        return Lamb(model_params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        return SGD(model_params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RAdam':\n",
    "        return RAdam(model_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(np.eye(3)[labels], F.softmax(outputs, dim=1).cpu().detach().numpy(), multi_class='ovr')\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    rmse = root_mean_squared_error(labels, preds)\n",
    "    return acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach())\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    outputs_cat = torch.cat(all_outputs)\n",
    "    labels_cat = torch.cat(all_labels)\n",
    "    acc, precision, recall, f1, roc_auc, rmse = compute_metrics(outputs_cat, labels_cat)\n",
    "    return total_loss / len(loader), acc, precision, recall, f1, roc_auc, rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for optimizer_name in optimizers_list:\n",
    "            \n",
    "            model = CLIPSkinClassifier(clip_model, num_classes=num_classes).to(device).float()\n",
    "            \n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = get_optimizer(optimizer_name,model.parameters(), lr=lr)\n",
    "            \n",
    "            \n",
    "            for epoch in range(start,total_epochs,step):\n",
    "                \n",
    "                \n",
    "                train_loss, train_acc, train_precision, train_recall, train_f1, train_roc_auc, train_rmse = train_model(model, train_loader, optimizer, criterion, device)\n",
    "                val_loss, val_acc, val_precision, val_recall, val_f1, val_roc_auc, val_rmse = evaluate_model(model, val_loader, criterion, device)\n",
    "                test_loss, test_acc, test_precision, test_recall, test_f1, test_roc_auc, test_rmse = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "\n",
    "                print(\"----------Values After Training-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\",\n",
    "                    f\"\\nOptimizer: {optimizer_name}, \\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                        f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train  F1: {train_f1:.4f},\"\n",
    "                        f\"Train ROC AUC: {train_roc_auc if train_roc_auc is not None else 'N/A'}, Train RMSE: {train_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Validation-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name}, \\nVal Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                            f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc if train_roc_auc is not None else 'N/A'}, \"\n",
    "                            f\"Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "                print(\"\\n\\n-----------Values After Testing-----------\")\n",
    "                print(f\"\\nEpoch: [{epoch}/{total_epochs}] \\nBatch Size: {batch_size} \\nLearning Rate: {lr}\"\n",
    "                    f\"\\nOptimizer: {optimizer_name}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, \"\n",
    "                            f\"Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}, Test ROC AUC: {test_roc_auc if train_roc_auc is not None else 'N/A'}, Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "                \n",
    "                \n",
    "                overall_result = {\n",
    "                    'Epoch': epoch ,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Learning Rate': lr,\n",
    "                    'Optimizer': optimizer_name,\n",
    "\n",
    "                    'Train Loss': round(train_loss, 4),\n",
    "                    'Test Loss': round(test_loss, 4),\n",
    "                    'Val Loss': round(val_loss, 4),\n",
    "\n",
    "                    'Train Acc': round(train_acc, 4),\n",
    "                    'Test Acc': round(test_acc, 4),\n",
    "                    'Val Acc': round(val_acc, 4),\n",
    "\n",
    "                    'Train Precision': round(train_precision, 4),\n",
    "                    'Test Precision': round(test_precision, 4),\n",
    "                    'Val Precision': round(val_precision, 4),\n",
    "\n",
    "                    'Train Recall': round(train_recall, 4),\n",
    "                    'Test Recall': round(test_recall, 4),\n",
    "                    'Val Recall': round(val_recall, 4),\n",
    "\n",
    "                    'Train F1 Score': round(train_f1, 4),\n",
    "                    'Test F1 Score': round(test_f1, 4),\n",
    "                    'Val F1 Score': round(val_f1, 4),\n",
    "\n",
    "                    'Train ROC AUC': round(train_roc_auc, 4) if train_roc_auc is not None else None,\n",
    "                    'Test ROC AUC': round(test_roc_auc, 4) if test_roc_auc is not None else None,\n",
    "                    'Val ROC AUC': round(val_roc_auc, 4) if val_roc_auc is not None else None,\n",
    "\n",
    "                    'Train RMSE': round(train_rmse, 4),\n",
    "                    'Test RMSE': round(test_rmse, 4),\n",
    "                    'Val RMSE': round(val_rmse, 4)\n",
    "                }\n",
    "\n",
    "                overall_result_file = 'Batch 8 all parameter testing.csv'\n",
    "                if not os.path.isfile(overall_result_file):\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, index=False)\n",
    "                else:\n",
    "                    pd.DataFrame([overall_result]).to_csv(overall_result_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928843ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
